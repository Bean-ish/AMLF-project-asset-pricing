{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed78849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "# According to note 30: \"Therefore, to predict returns at month t+1, we use most recent monthly characteristics at the end of month t.\" <br>\n",
    "# Hence, **shift return t+1 to serve as response: r(t+1)**.\n",
    "\n",
    "df['r(t+1)'] = df.groupby('permno')['return'].shift(-1)\n",
    "\n",
    "### handle missing data\n",
    "\n",
    "# According to note 30 (bottom of p 2248): \"Another issue is missing characteristics, which we replace with the cross-sectional median at each month for each stock, respectively.\" <br>\n",
    "# Hence, calculate monthly cross-sectional median for features: **'mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr'**.\n",
    "\n",
    "df_filled = df.copy()\n",
    "for feature in ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']:\n",
    "    df_filled[feature] = df_filled.groupby('Date')[feature].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df_filled.isna().sum()\n",
    "\n",
    "df.loc[:, ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']] = df_filled.loc[:,['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']]\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bee966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the datetime column as index\n",
    "df.set_index('Date', inplace=True, drop = True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "\n",
    "permno = df['permno'].reset_index(drop = True)\n",
    "\n",
    "df_scaled['permno'] = permno\n",
    "\n",
    "df_scaled.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bea3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.reset_index()  # bring back date column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac092456",
   "metadata": {},
   "source": [
    "use dataframe: df_scaled<br>\n",
    "try not to reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2168d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['permno', 'SICCD', 'NCUSIP', 'TICKER', 'COMNAM'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = pd.read_csv('Companies.csv')\n",
    "companies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d44444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(companies['permno'].unique()))\n",
    "\n",
    "# companies_with_duplicates = companies[companies.duplicated(subset=['permno'], keep=False)]\n",
    "# companies_with_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b7d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = companies.sort_values(by='permno')\n",
    "\n",
    "upd_companies = companies.groupby('permno').tail(1)\n",
    "\n",
    "# only get the lasted info for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e513ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6669 companies dont have SIC code\n",
    "\n",
    "# print(upd_companies['SICCD'].isna().values.sum())\n",
    "# print(len(upd_companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b4ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(df_scaled, upd_companies, on='permno', how='left')\n",
    "merged_data = merged_data.drop(columns = ['NCUSIP', 'TICKER'])\n",
    "\n",
    "# print(merged_data['SICCD'].isna().values.sum())\n",
    "# print(merged_data['SICCD'].isna().values.sum()/228)            # drop 135 companies from the dataset that doesn't have sic\n",
    "\n",
    "merged_data = merged_data[merged_data['SICCD'].notna()]\n",
    "\n",
    "merged_data.to_csv('merged_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4b363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
