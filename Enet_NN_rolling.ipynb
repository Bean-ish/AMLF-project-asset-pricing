{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e35d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdfe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/users/LL/Documents/GitHub/AMLF_projects/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9bfc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485ca046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>permno</th>\n",
       "      <th>return</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>chmom</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom36m</th>\n",
       "      <th>turn</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>...</th>\n",
       "      <th>baspread</th>\n",
       "      <th>retvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>ep</th>\n",
       "      <th>sp</th>\n",
       "      <th>agr</th>\n",
       "      <th>nincr</th>\n",
       "      <th>return(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13610</td>\n",
       "      <td>-0.202242</td>\n",
       "      <td>0.277978</td>\n",
       "      <td>-0.082232</td>\n",
       "      <td>0.518490</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>-0.258322</td>\n",
       "      <td>0.820391</td>\n",
       "      <td>9.897840e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>0.398706</td>\n",
       "      <td>0.158967</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>1.472909</td>\n",
       "      <td>0.325935</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13856</td>\n",
       "      <td>-0.112756</td>\n",
       "      <td>0.095372</td>\n",
       "      <td>0.300233</td>\n",
       "      <td>-0.147620</td>\n",
       "      <td>0.069669</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.660636</td>\n",
       "      <td>7.152231e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033983</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.039970</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13901</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.166088</td>\n",
       "      <td>0.759861</td>\n",
       "      <td>0.504130</td>\n",
       "      <td>0.400659</td>\n",
       "      <td>-0.440929</td>\n",
       "      <td>0.775189</td>\n",
       "      <td>9.783550e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>0.050243</td>\n",
       "      <td>0.088382</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>1.148088</td>\n",
       "      <td>-0.024383</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13928</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.039925</td>\n",
       "      <td>0.400659</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>0.813903</td>\n",
       "      <td>1.451888e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>0.159983</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.051091</td>\n",
       "      <td>1.138525</td>\n",
       "      <td>-0.069288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13936</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.574141</td>\n",
       "      <td>0.224657</td>\n",
       "      <td>-0.075486</td>\n",
       "      <td>-0.397110</td>\n",
       "      <td>0.755288</td>\n",
       "      <td>3.550430e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031413</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>1.060490</td>\n",
       "      <td>1.124640</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>6.902488</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  permno    return     mom1m    mom12m     chmom    indmom  \\\n",
       "0  2001-01-31   13610 -0.202242  0.277978 -0.082232  0.518490  0.198455   \n",
       "1  2001-01-31   13856 -0.112756  0.095372  0.300233 -0.147620  0.069669   \n",
       "2  2001-01-31   13901  0.010566  0.166088  0.759861  0.504130  0.400659   \n",
       "3  2001-01-31   13928  0.033114  0.006637  0.236486  0.039925  0.400659   \n",
       "4  2001-01-31   13936  0.014335  0.009709  0.574141  0.224657 -0.075486   \n",
       "\n",
       "     mom36m      turn         mvel1  ...  baspread    retvol   idiovol  \\\n",
       "0 -0.258322  0.820391  9.897840e+05  ...  0.037278  0.032888  0.056769   \n",
       "1  0.000718  0.660636  7.152231e+07  ...  0.033983  0.022389  0.042020   \n",
       "2 -0.440929  0.775189  9.783550e+07  ...  0.032844  0.023475  0.050243   \n",
       "3  0.025686  0.813903  1.451888e+07  ...  0.035964  0.023917  0.037427   \n",
       "4 -0.397110  0.755288  3.550430e+05  ...  0.031413  0.030343  0.068491   \n",
       "\n",
       "       beta    betasq        ep        sp       agr  nincr  return(t-1)  \n",
       "0  0.398706  0.158967  0.019041  1.472909  0.325935    5.0          NaN  \n",
       "1  0.106574  0.011358  0.039970  0.397105  0.225463    1.0          NaN  \n",
       "2  0.088382  0.007811  0.142695  1.148088 -0.024383    2.0          NaN  \n",
       "3  0.159983  0.025595  0.051091  1.138525 -0.069288    1.0          NaN  \n",
       "4  1.060490  1.124640  0.091598  6.902488  0.000838    0.0          NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0fa84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Index(['Date', 'permno', 'return', 'mom1m', 'mom12m', 'chmom', 'indmom',\n",
      "       'mom36m', 'turn', 'mvel1', 'dolvol', 'ill', 'zerotrade', 'baspread',\n",
      "       'retvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr',\n",
      "       'return(t-1)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46799c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         12.968131\n",
       "1         17.527472\n",
       "2         17.773933\n",
       "3         16.111030\n",
       "4         12.518458\n",
       "            ...    \n",
       "113995    10.203254\n",
       "113996     9.558279\n",
       "113997    11.116588\n",
       "113998    14.259460\n",
       "113999    14.433653\n",
       "Name: dolvol, Length: 114000, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dolvol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cccd2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            object\n",
       "permno           int64\n",
       "return         float64\n",
       "mom1m          float64\n",
       "mom12m         float64\n",
       "chmom          float64\n",
       "indmom         float64\n",
       "mom36m         float64\n",
       "turn           float64\n",
       "mvel1          float64\n",
       "dolvol         float64\n",
       "ill            float64\n",
       "zerotrade      float64\n",
       "baspread       float64\n",
       "retvol         float64\n",
       "idiovol        float64\n",
       "beta           float64\n",
       "betasq         float64\n",
       "ep             float64\n",
       "sp             float64\n",
       "agr            float64\n",
       "nincr          float64\n",
       "return(t-1)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64903994",
   "metadata": {},
   "source": [
    "According to note 30: \"Therefore, to predict returns at month t+1, we use most recent monthly characteristics at the end of month t.\" <br>\n",
    "Hence, **shift return t+1 to serve as response: r(t+1)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r(t+1)'] = df.groupby('permno')['return'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1d5769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1521d1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "permno            0\n",
       "return            0\n",
       "mom1m             3\n",
       "mom12m          269\n",
       "chmom           269\n",
       "indmom            0\n",
       "mom36m         1566\n",
       "turn              9\n",
       "mvel1             0\n",
       "dolvol            6\n",
       "ill               0\n",
       "zerotrade         0\n",
       "baspread          0\n",
       "retvol            0\n",
       "idiovol         352\n",
       "beta            352\n",
       "betasq          352\n",
       "ep              473\n",
       "sp              473\n",
       "agr            1026\n",
       "nincr          2794\n",
       "return(t-1)     500\n",
       "r(t+1)          500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110f651",
   "metadata": {},
   "source": [
    "### handle missing data\n",
    "\n",
    "According to note 30 (bottom of p 2248): \"Another issue is missing characteristics, which we replace with the cross-sectional median at each month for each stock, respectively.\" <br>\n",
    "Hence, calculate monthly cross-sectional median for features: **'mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581efc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.copy()\n",
    "for feature in ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']:\n",
    "    df_filled[feature] = df_filled.groupby('Date')[feature].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8094662b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d22efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']] = df_filled.loc[:,['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9379e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4352d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the datetime column as index\n",
    "df.set_index('Date', inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b1f46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff8f4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "permno = df['permno'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "822df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['permno'] = permno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a730d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e5993c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_2 = df_scaled.drop(columns = [ 'permno', 'return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cea22",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad622f5c",
   "metadata": {},
   "source": [
    "**split training, validation, and testing datasets**\n",
    "\n",
    "training : validation : testing = 6 yr : 4yr : 9 yr <br>\n",
    "Also drop the first and last month due to the absence of r(t+1) and return(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c7915c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = df_scaled[:'2007-01-01'].dropna()\n",
    "# validation = df_scaled['2007-01-01':'2011-01-01']\n",
    "# testing = df_scaled['2011-01-01':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd1f3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_combined = df_scaled[:'2011-01-01'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613068a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd311e5b",
   "metadata": {},
   "source": [
    "**separate X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef894e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = training.drop(columns = ['r(t+1)'])\n",
    "# y_train = training['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "513ee4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = validation.drop(columns = ['r(t+1)'])\n",
    "# y_val = validation['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b557f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = testing.drop(columns = ['r(t+1)'])\n",
    "# y_test = testing['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b683b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_combined = training_combined.drop(columns = ['r(t+1)'])\n",
    "# y_train_combined = training_combined['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5127d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.isna().values.sum())\n",
    "# print(X_val.isna().values.sum())\n",
    "# print(X_test.isna().values.sum())\n",
    "# print(y_train.isna().values.sum())\n",
    "# print(y_val.isna().values.sum())\n",
    "# print(y_test.isna().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15eb2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training.shape)\n",
    "# print(validation.shape)\n",
    "# print(testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4ab11",
   "metadata": {},
   "source": [
    "### generate rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0946f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rolling_windows(data, total_years, initial_train_size, val_size):\n",
    "    total_years = total_years\n",
    "    windows = []\n",
    "    initial_train_size = initial_train_size\n",
    "    val_size = val_size\n",
    "\n",
    "    # Loop through the years to create rolling windows\n",
    "    for i in range(initial_train_size + 1, total_years-val_size):\n",
    "        idx_1 = '20' + str(i).zfill(2) + '-01-01'\n",
    "        idx_2 = '20' + str(i + val_size).zfill(2) + '-01-01'\n",
    "        \n",
    "        training = data[:idx_1].dropna()\n",
    "        validation = data[idx_1:idx_2]\n",
    "        testing = data[idx_2:].dropna()\n",
    "        \n",
    "        train_com = data[:idx_2].dropna()\n",
    "\n",
    "        windows.append((training, validation, testing, train_com))\n",
    "        \n",
    "    return windows\n",
    "\n",
    "\n",
    "# for inital split: training, validation, testing, train_combined \n",
    "#                       - windows[0][0], windows[0][1], windows[0][2], windows[0][3]\n",
    "\n",
    "# increase the first index by 1 using for loop to fit all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5a4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling samples\n",
    "\n",
    "windows = generate_rolling_windows(df_scaled_2, 19, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39a02f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2beec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bab15222",
   "metadata": {},
   "source": [
    "### subsetting data: top and bottom 100 stocks on market value (mvel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e27b0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0756555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvel_sorted_top = subset['2019-12-01':].sort_values('mvel1',ascending=False).head(100).reset_index(drop=True)\n",
    "filter_values_top = mvel_sorted_top['permno']\n",
    "top_100 = subset[subset['permno'].isin(filter_values_top)]\n",
    "\n",
    "\n",
    "mvel_sorted_bot = subset['2019-12-01':].sort_values('mvel1',ascending=False).tail(100).reset_index(drop=True)\n",
    "filter_values_bot = mvel_sorted_bot['permno']\n",
    "bot_100 = subset[subset['permno'].isin(filter_values_bot)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c8ff898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22800, 23)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100.shape\n",
    "# 19*12*10 = 2280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9305903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c03273f",
   "metadata": {},
   "source": [
    "**splitting data & separating X and y** <br>\n",
    "***\n",
    "splitting data 10:9 years - to make the training set the same size as the training and validation set combined, leave testing set out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb14aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_top = top_100[:'2011-01-01'].dropna()\n",
    "testing_top = top_100['2011-01-02':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "482d1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bot = bot_100[:'2011-01-01'].dropna()\n",
    "testing_bot = bot_100['2011-01-02':].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e2063",
   "metadata": {},
   "source": [
    "separating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a29d3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_top = testing_top.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test_top = testing_top['r(t+1)']\n",
    "\n",
    "X_test_bot = testing_bot.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test_bot = testing_bot['r(t+1)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8b1b0",
   "metadata": {},
   "source": [
    "## packages & custom funcs\n",
    "***\n",
    "1. R^2 without demeaning\n",
    "2. tuning_1: fixed set hyperparameter tuning\n",
    "3. tuning: recursive rolling tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a0a667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce231db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r^2-oos for Enet\n",
    "\n",
    "def r2_score_wo_demeaning(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    ss_res = 0\n",
    "    ss_tot = 0\n",
    "    for i in range(len(y_true)):\n",
    "        ss_res = ss_res + ((y_true[i] - y_pred[i])**2)\n",
    "        ss_tot = ss_tot + ((y_true[i] - 0)**2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return float(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1557d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_1 (model, param_combos, X_train, y_train, X_val, y_val):\n",
    "#   param_combos: list of dictionaries of parameters combo\n",
    "    \n",
    "    results = {'param': [], 'score': []}\n",
    "    opt_param = 0\n",
    "    opt_score = 0\n",
    "\n",
    "    for params in param_combos:\n",
    "\n",
    "        for param_name, param_value in params.items():\n",
    "            setattr(model, param_name, param_value)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "#         print(\"Shape of y_val:\", y_val.shape)\n",
    "#         print(\"Shape of y_pred:\", y_pred.shape)\n",
    "        \n",
    "        r2 = r2_score_wo_demeaning(y_val, y_pred)\n",
    "\n",
    "        results['param'].append(params)\n",
    "        results['score'].append(r2)\n",
    "    \n",
    "    sorted_zipped = sorted(zip(results['param'], results['score']), key=lambda x: x[1])\n",
    "    opt_param = sorted_zipped[0][0]\n",
    "    opt_score = sorted_zipped[0][1]\n",
    "    \n",
    "    return opt_param, opt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35d57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e918c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9682d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e3ce901",
   "metadata": {},
   "source": [
    "## Enet\n",
    "\n",
    "\n",
    "prediction: g*(z i,t) - depends on neither i nor t, is dependend on z only through z i,t <br>\n",
    "responses: r i, t+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf763cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d566281",
   "metadata": {},
   "source": [
    "**tuning**\n",
    "\n",
    "1. set-up the search grid\n",
    "2. tuning: recursive rolling validation set w/ oos R^2 metric -- <br>\n",
    "    roll one unit froward each time and take the average as the final score <br>\n",
    "3. pick the best hyperparameters, retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62b1cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up searching grid\n",
    "\n",
    "alpha_values = [0.4, 0.5, 0.6]\n",
    "l1_ratio_values = np.logspace(-4, -1, 10)\n",
    "\n",
    "param_enet = [{'alpha': alpha, 'l1_ratio': l1_ratio} for alpha in alpha_values for l1_ratio in l1_ratio_values]\n",
    "\n",
    "# for param_combination in param_combinations:\n",
    "#     print(param_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "027fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "\n",
    "Enet = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d6424ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is 0.0007755796797865866.\n",
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is 0.002077004617268674.\n",
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is -0.0014524607777255394.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0063834100482236256.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.004957498963627627.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0035499187056395876.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0012202180037492738.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0022601722569968175.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for window in windows:\n",
    "    \n",
    "    #apply tuning function\n",
    "    result = tuning_1(Enet, param_enet, window[0].drop(columns = ['r(t+1)']), window[0]['r(t+1)'], window[1].drop(columns = ['r(t+1)']), window[1]['r(t+1)'])\n",
    "    \n",
    "    # print out tuning parameters of eah]ch split\n",
    "    print(f\"the optimal parameters are {result[0]} and the best score is {result[1]}.\")\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "779c0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for window in windows:\n",
    "#     print(window[0].drop(columns = ['r(t+1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bedc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f2c02ec",
   "metadata": {},
   "source": [
    "**best model** <br>\n",
    "<br>\n",
    "Fit on all data in training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d106cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Enet_opt = ElasticNet()\n",
    "r2_Enet = []\n",
    "r2_Enet_top = []\n",
    "r2_Enet_bot = []\n",
    "for i in range(8):\n",
    "    \n",
    "    for param_name, param_value in results[i][0].items():\n",
    "     setattr(Enet_opt, param_name, param_value)\n",
    "    \n",
    "    Enet_opt.fit(windows[i][3].drop(columns = ['r(t+1)']), windows[i][3]['r(t+1)'])\n",
    "    y_pred_enet = Enet_opt.predict(windows[i][2].drop(columns = ['r(t+1)']))\n",
    "    \n",
    "    r2_enet = r2_score_wo_demeaning(windows[i][2]['r(t+1)'], y_pred_enet)\n",
    "    r2_Enet.append(r2_enet)       # fit best model for each split\n",
    "    \n",
    "    # used model to generate prediction for the top 100\n",
    "    y_pred_enet_top = Enet_opt.predict(X_test_top)\n",
    "    r2_enet_top = r2_score_wo_demeaning(y_test_top, y_pred_enet_top)\n",
    "    r2_Enet_top.append(r2_enet_top)\n",
    "    \n",
    "    y_pred_enet_bot = Enet_opt.predict(X_test_bot)\n",
    "    r2_enet_bot = r2_score_wo_demeaning(y_test_bot, y_pred_enet_bot)\n",
    "    r2_Enet_bot.append(r2_enet_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ecffeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005663579684225262,\n",
       " 0.0007243052297416508,\n",
       " 0.00015885305985385845,\n",
       " -0.001960710816258926,\n",
       " -0.0008903639645345685,\n",
       " 2.6038543099682343e-05,\n",
       " -0.002316165787667135,\n",
       " -0.00016025654555895663]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the best r^2-oos for 8 splits stored in one list:\n",
    "\n",
    "r2_Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e15f001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2-oos: -0.0004814927891127335\n"
     ]
    }
   ],
   "source": [
    "#take average\n",
    "\n",
    "print(\"R^2-oos:\", sum(r2_Enet) / len(r2_Enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091852f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71740d28",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cb7d04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0026816164329585,\n",
       " 0.0032536355833986397,\n",
       " 0.0033384827679580065,\n",
       " -0.014004771665988347,\n",
       " -0.013416054442168646,\n",
       " -0.017310167694035927,\n",
       " -0.011820903699103269,\n",
       " -0.008782282295214605]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_Enet_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c324fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 stocks R^2-oos: -0.007007555626524456\n"
     ]
    }
   ],
   "source": [
    "# take average\n",
    "\n",
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_Enet_top) / len(r2_Enet_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05f088ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.002231535569684029,\n",
       " -0.0009302732914853173,\n",
       " -0.0010422973876647035,\n",
       " -0.005407781758678176,\n",
       " -0.004479592866621029,\n",
       " -0.002450936187006425,\n",
       " -0.0032335221090211697,\n",
       " -0.0031839051781878958]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_Enet_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e12d2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 100 stocks R^2-oos: -0.0028699805435435932\n"
     ]
    }
   ],
   "source": [
    "# take average\n",
    "\n",
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_Enet_bot) / len(r2_Enet_bot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77969a4c",
   "metadata": {},
   "source": [
    "**feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# coefficients = Enet_opt.coef_\n",
    "\n",
    "# # Get feature names\n",
    "# # Assuming feature_names is a list of your feature names\n",
    "# feature_names = X_train_combined.columns  # Insert your feature names here\n",
    "\n",
    "# # Create a dictionary to store feature importance scores with feature names\n",
    "# feature_importance_dict = dict(zip(feature_names, np.abs(coefficients)))\n",
    "\n",
    "# # Sort feature importance dictionary by importance score\n",
    "# sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Extract feature names and importance scores after sorting\n",
    "# sorted_feature_names = [x[0] for x in sorted_feature_importance]\n",
    "# sorted_feature_importance_scores = [x[1] for x in sorted_feature_importance]\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.barh(sorted_feature_names, sorted_feature_importance_scores)\n",
    "# plt.xlabel('Feature Importance')\n",
    "# plt.ylabel('Features')\n",
    "# plt.title('Feature Importance of Elastic Net Model')\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to have the most important features at the top\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2054aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f12888",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ca69c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c328bf",
   "metadata": {},
   "source": [
    "**loss function**\n",
    "\n",
    "Customize the loss function to be **\"penalized cross-sectional average prediction error\" (appendix B.3) aggregated over time**, which is the same as **penalized l2 objective function of prediction errors (p2244)**. <br>\n",
    "***\n",
    "penalty term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13872e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_pcape (y_true, y_pred):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e9b7d",
   "metadata": {},
   "source": [
    "**performance metric**\n",
    "\n",
    "Out-of-sample R^2. (r2_score_wo_demeaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35e44da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def r2_score_wo_demeaning_nn(y_true, y_pred):\n",
    "    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    ss_tot = tf.reduce_sum(tf.square(y_true - 0))\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599f72c",
   "metadata": {},
   "source": [
    "**tuning custom function for neural net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32b3c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_and_tune_model(model, parameter_dicts, x_train, y_train, x_val, y_val):\n",
    "    results = []\n",
    "    \n",
    "    for params in parameter_dicts:\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "                      loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)  # Using mean absolute error (mae) as metric\n",
    "        \n",
    "        history = model.fit(x_train, y_train, epochs=params['epoch'], batch_size=params['batch_size'],\n",
    "                            validation_data=(x_val, y_val), verbose=0)\n",
    "        \n",
    "        # Get the metric value for the last epoch\n",
    "        last_epoch_metric = history.history['r2_score_wo_demeaning_nn'][-1]  # Validation MAE for last epoch\n",
    "        \n",
    "        # Store results for current parameter set\n",
    "        results.append({'params': params, 'val_r2_score_wo_demeaning_nn': last_epoch_metric})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d6471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d292e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f85419",
   "metadata": {},
   "source": [
    "### model\n",
    "\n",
    "All activation functions are ReLU function <br>\n",
    "optimizer: SGD w/ learning rate shrinkage: adam <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0ff5a",
   "metadata": {},
   "source": [
    "convert dataframes to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a6931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a4b2d0",
   "metadata": {},
   "source": [
    "set-up grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72655500",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch_val = [25, 50, 75, 100]\n",
    "lr_val = [0.05, 0.025, 0.01]\n",
    "nbatch_val = [1000, 1500, 3000]\n",
    "\n",
    "param_nn = [{'epoch': epoch, 'learning_rate': learning_rate, 'batch_size': batch_size} for epoch in nepoch_val for learning_rate in lr_val for batch_size in nbatch_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1f391",
   "metadata": {},
   "source": [
    "**1-layer** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4beffabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = 20\n",
    "layer1_n = 32\n",
    "\n",
    "model_1 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc86773",
   "metadata": {},
   "source": [
    "tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24f097c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m y_train_combined_nn \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(window[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr(t+1)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# apply function\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m result_nn1 \u001b[38;5;241m=\u001b[39m compile_and_tune_model(model_1, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# get score\u001b[39;00m\n\u001b[0;32m     24\u001b[0m result_nn1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result_nn1)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_r2_score_wo_demeaning_nn\u001b[39m\u001b[38;5;124m'\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[64], line 9\u001b[0m, in \u001b[0;36mcompile_and_tune_model\u001b[1;34m(model, parameter_dicts, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m parameter_dicts:\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      7\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39mr2_score_wo_demeaning_nn)  \u001b[38;5;66;03m# Using mean absolute error (mae) as metric\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     10\u001b[0m                         validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Get the metric value for the last epoch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     last_epoch_metric \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_score_wo_demeaning_nn\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Validation MAE for last epoch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_nn1 = []\n",
    "opt_scores_nn1 = []\n",
    "opt_paras_nn1 = []\n",
    "\n",
    "for window in windows:\n",
    "    \n",
    "    # to arry\n",
    "    X_train_nn = np.asarray(window[0].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_nn = np.asarray(window[0]['r(t+1)'].values)\n",
    "\n",
    "    X_val_nn = np.asarray(window[1].drop(columns = ['r(t+1)']).values)\n",
    "    y_val_nn = np.asarray(window[1]['r(t+1)'].values)\n",
    "    \n",
    "    # apply function\n",
    "    result_nn1 = compile_and_tune_model(model_1, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n",
    "    \n",
    "    # get score\n",
    "    result_nn1 = pd.DataFrame(result_nn1).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "    opt_score = result_nn1.iloc[0,1]\n",
    "    opt_para = result_nn1.iloc[0,0]\n",
    "    # results_nn1.append(result_nn1.iloc[0,])\n",
    "    opt_scores_nn1.append(opt_score)\n",
    "    opt_paras_nn1.append(opt_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcdc47",
   "metadata": {},
   "source": [
    "best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c72a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aba3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn1.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b687a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn1.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn1 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "last_epoch_metrics = []\n",
    "r2_nn1_tops = []\n",
    "r2_nn1_bots = []\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    model_nn1.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "    X_train_combined_nn = np.asarray(windows[i][3].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_combined_nn = np.asarray(windows[i][3]['r(t+1)'].values)\n",
    "    \n",
    "    X_test_nn = np.asarray(windows[i][2].drop(columns = ['r(t+1)']).values)\n",
    "    y_test_nn = np.asarray(windows[i][2]['r(t+1)'].values)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model_nn1.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_paras_nn1[i]['epoch'], batch_size=opt_paras_nn1[i]['batch_size'],\n",
    "                                validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "    # get scores\n",
    "    last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "    last_epoch_metrics.append(last_epoch_metric)\n",
    "\n",
    "    \n",
    "    # top 100\n",
    "    y_pred_nn1_top = model_nn1.predict(X_test_top)\n",
    "    r2_nn1_top = r2_score_wo_demeaning(y_test_top, y_pred_nn1_top)\n",
    "    r2_nn1_tops.append(r2_nn1_top)\n",
    "    \n",
    "    # bot 100\n",
    "    y_pred_nn1_bot = model_nn1.predict(X_test_bot)\n",
    "    r2_nn1_bot = r2_score_wo_demeaning(y_test_bot, y_pred_nn1_bot)\n",
    "    r2_nn1_bots.append(r2_nn1_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NN1 average R^2-oos:\", sum(last_epoch_metrics) / len(last_epoch_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f2aeb",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3259fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn1_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f893d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn1_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_nn1_tops) / len(r2_nn1_tops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c87e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_nn1_bots) / len(r2_nn1_bots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968300d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db3d8800",
   "metadata": {},
   "source": [
    "**3-layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 20\n",
    "layer1_n = 32\n",
    "layer2_n = 16\n",
    "layer3_n = 8\n",
    "\n",
    "\n",
    "model_3 = Sequential([\n",
    "            layers.Dense(layer1_n, input_dim = input_dim, activation='relu'),\n",
    "            layers.Dense(layer2_n, activation='relu'),\n",
    "            layers.Dense(layer3_n, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a2cd7",
   "metadata": {},
   "source": [
    "tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn3 = []\n",
    "opt_scores_nn3 = []\n",
    "opt_paras_nn3 = []\n",
    "\n",
    "for window in windows:\n",
    "    \n",
    "    # to arry\n",
    "    X_train_nn = np.asarray(window[0].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_nn = np.asarray(window[0]['r(t+1)'].values)\n",
    "\n",
    "    X_val_nn = np.asarray(window[1].drop(columns = ['r(t+1)']).values)\n",
    "    y_val_nn = np.asarray(window[1]['r(t+1)'].values)\n",
    "\n",
    "    result_nn3 = compile_and_tune_model(model_3, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n",
    "    \n",
    "    # get score\n",
    "    result_nn3 = pd.DataFrame(result_nn3).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "    opt_score = result_nn3.iloc[0,1]\n",
    "    opt_para = result_nn3.iloc[0,0]\n",
    "    # results_nn1.append(result_nn1.iloc[0,])\n",
    "    opt_scores_nn3.append(opt_score)\n",
    "    opt_paras_nn3.append(opt_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72842f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a928625c",
   "metadata": {},
   "source": [
    "best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a56a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn3 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(layer2_n, activation='relu'),\n",
    "            layers.Dense(layer3_n, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "last_epoch_metrics_nn3 = []\n",
    "r2_nn3_tops = []\n",
    "r2_nn3_bots = []\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    model_nn3.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "    X_train_combined_nn = np.asarray(windows[i][3].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_combined_nn = np.asarray(windows[i][3]['r(t+1)'].values)\n",
    "    \n",
    "    X_test_nn = np.asarray(windows[i][2].drop(columns = ['r(t+1)']).values)\n",
    "    y_test_nn = np.asarray(windows[i][2]['r(t+1)'].values)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model_nn3.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_paras_nn3[i]['epoch'], batch_size=opt_paras_nn3[i]['batch_size'],\n",
    "                                validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "    # get scores\n",
    "    last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "    last_epoch_metrics_nn3.append(last_epoch_metric)\n",
    "\n",
    "    \n",
    "    # top 100\n",
    "    y_pred_nn3_top = model_nn3.predict(X_test_top)\n",
    "    r2_nn3_top = r2_score_wo_demeaning(y_test_top, y_pred_nn3_top)\n",
    "    r2_nn3_tops.append(r2_nn3_top)\n",
    "    \n",
    "    # bot 100\n",
    "    y_pred_nn3_bot = model_nn1.predict(X_test_bot)\n",
    "    r2_nn3_bot = r2_score_wo_demeaning(y_test_bot, y_pred_nn3_bot)\n",
    "    r2_nn3_bots.append(r2_nn3_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch_metrics_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NN3 average R^2-oos:\", sum(last_epoch_metrics_nn3) / len(last_epoch_metrics_nn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbd094",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn1_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d63c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn1_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_nn1_tops) / len(r2_nn1_tops))\n",
    "\n",
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_nn1_bots) / len(r2_nn1_bots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a035e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee19e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn3 = pd.DataFrame(result_nn3).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "# opt_score = result_nn3.iloc[0,1]\n",
    "# opt_para = result_nn3.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e11871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn3.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed235fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn3.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c61569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_nn3.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para['learning_rate']),\n",
    "#                       loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "# history = model_nn3.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_para['epoch'], batch_size=opt_para['batch_size'],\n",
    "#                             validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "        \n",
    "# last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
