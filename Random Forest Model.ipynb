{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cba0c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf18d3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07be86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "005cc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c0cb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r(t+1)'] = df.groupby('permno')['return'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "818362a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e2c7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.copy()\n",
    "for feature in ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']:\n",
    "    df_filled[feature] = df_filled.groupby('Date')[feature].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "497d9787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1e9f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']] = df_filled.loc[:,['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "745aca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvel_sorted = df.sort_values('mvel1',ascending=False)\n",
    "top_100 = mvel_sorted.groupby('Date').head(100).reset_index(drop=True)\n",
    "bottom_100 = mvel_sorted.groupby('Date').tail(100).reset_index(drop=True)\n",
    "top_100.set_index('Date', inplace=True)\n",
    "bottom_100.set_index('Date', inplace=True)\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ac410db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bae86",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1a437154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rolling_windows(data, total_years, initial_train_size, val_size):\n",
    "    total_years = total_years\n",
    "    windows = []\n",
    "    initial_train_size = initial_train_size\n",
    "    val_size = val_size\n",
    "\n",
    "    # Loop through the years to create rolling windows\n",
    "    for i in range(initial_train_size + 1, total_years-val_size):\n",
    "        idx_1 = '20' + str(i).zfill(2) + '-01-01'\n",
    "        idx_2 = '20' + str(i + val_size).zfill(2) + '-01-01'\n",
    "        \n",
    "        training = data[:idx_1].dropna()\n",
    "        validation = data[idx_1:idx_2]\n",
    "        testing = data[idx_2:].dropna()\n",
    "        \n",
    "        train_com = data[:idx_2].dropna()\n",
    "\n",
    "        windows.append((training, validation, testing, train_com))\n",
    "        \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4c01fa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>return</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>chmom</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom36m</th>\n",
       "      <th>turn</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>...</th>\n",
       "      <th>retvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>ep</th>\n",
       "      <th>sp</th>\n",
       "      <th>agr</th>\n",
       "      <th>nincr</th>\n",
       "      <th>return(t-1)</th>\n",
       "      <th>r(t+1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>13610</td>\n",
       "      <td>0.161318</td>\n",
       "      <td>-0.190508</td>\n",
       "      <td>0.327877</td>\n",
       "      <td>0.249243</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>-0.285854</td>\n",
       "      <td>1.023598</td>\n",
       "      <td>8.012218e+05</td>\n",
       "      <td>13.974887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028112</td>\n",
       "      <td>0.058059</td>\n",
       "      <td>0.385289</td>\n",
       "      <td>0.148447</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>1.472909</td>\n",
       "      <td>0.325935</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.202242</td>\n",
       "      <td>-0.009186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>13856</td>\n",
       "      <td>0.046940</td>\n",
       "      <td>-0.110820</td>\n",
       "      <td>0.471192</td>\n",
       "      <td>-0.384316</td>\n",
       "      <td>0.115779</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>0.691164</td>\n",
       "      <td>6.359623e+07</td>\n",
       "      <td>17.810579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>0.118710</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>0.039970</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.112756</td>\n",
       "      <td>-0.041659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>13901</td>\n",
       "      <td>0.094426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.261056</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>0.682048</td>\n",
       "      <td>-0.446731</td>\n",
       "      <td>0.829092</td>\n",
       "      <td>9.783550e+07</td>\n",
       "      <td>17.863872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>0.050186</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>1.148088</td>\n",
       "      <td>-0.024383</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.002179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>13928</td>\n",
       "      <td>-0.084292</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>0.431206</td>\n",
       "      <td>-0.111444</td>\n",
       "      <td>0.682048</td>\n",
       "      <td>-0.021776</td>\n",
       "      <td>0.842627</td>\n",
       "      <td>1.496689e+07</td>\n",
       "      <td>16.501171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.038102</td>\n",
       "      <td>0.142332</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.051091</td>\n",
       "      <td>1.138525</td>\n",
       "      <td>-0.069288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>0.034813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>13936</td>\n",
       "      <td>0.149662</td>\n",
       "      <td>-0.006923</td>\n",
       "      <td>0.957347</td>\n",
       "      <td>0.098914</td>\n",
       "      <td>-0.032018</td>\n",
       "      <td>-0.421654</td>\n",
       "      <td>0.820512</td>\n",
       "      <td>3.525850e+05</td>\n",
       "      <td>12.565110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045878</td>\n",
       "      <td>0.068790</td>\n",
       "      <td>1.022686</td>\n",
       "      <td>1.045888</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>6.902488</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.031713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>89279</td>\n",
       "      <td>0.048871</td>\n",
       "      <td>0.024940</td>\n",
       "      <td>-0.031547</td>\n",
       "      <td>0.072748</td>\n",
       "      <td>0.098944</td>\n",
       "      <td>-0.027805</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>9.697706e+04</td>\n",
       "      <td>9.063220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.115212</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.060214</td>\n",
       "      <td>0.254025</td>\n",
       "      <td>-0.042325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026024</td>\n",
       "      <td>-0.004154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>89317</td>\n",
       "      <td>-0.054903</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>-0.275862</td>\n",
       "      <td>0.327413</td>\n",
       "      <td>0.163590</td>\n",
       "      <td>0.304287</td>\n",
       "      <td>0.025187</td>\n",
       "      <td>1.166978e+05</td>\n",
       "      <td>7.426549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016572</td>\n",
       "      <td>0.040691</td>\n",
       "      <td>0.271733</td>\n",
       "      <td>0.073839</td>\n",
       "      <td>-0.130443</td>\n",
       "      <td>0.836804</td>\n",
       "      <td>-0.183381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097319</td>\n",
       "      <td>-0.128977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>89456</td>\n",
       "      <td>0.160222</td>\n",
       "      <td>-0.045905</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.342970</td>\n",
       "      <td>0.085635</td>\n",
       "      <td>0.545880</td>\n",
       "      <td>1.244986</td>\n",
       "      <td>3.647852e+05</td>\n",
       "      <td>13.235699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>0.054782</td>\n",
       "      <td>1.819325</td>\n",
       "      <td>3.309943</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1.019684</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.041839</td>\n",
       "      <td>-0.024223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>89790</td>\n",
       "      <td>-0.018619</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-0.213837</td>\n",
       "      <td>-0.241931</td>\n",
       "      <td>0.068689</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>0.814450</td>\n",
       "      <td>5.602500e+04</td>\n",
       "      <td>10.551278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027389</td>\n",
       "      <td>0.110512</td>\n",
       "      <td>2.490410</td>\n",
       "      <td>6.202142</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.353447</td>\n",
       "      <td>-0.066737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084549</td>\n",
       "      <td>-0.058698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>89915</td>\n",
       "      <td>-0.027124</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.035572</td>\n",
       "      <td>0.263321</td>\n",
       "      <td>0.122462</td>\n",
       "      <td>1.197060</td>\n",
       "      <td>0.672472</td>\n",
       "      <td>7.856415e+05</td>\n",
       "      <td>12.643065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026306</td>\n",
       "      <td>0.042038</td>\n",
       "      <td>1.130174</td>\n",
       "      <td>1.277294</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.394275</td>\n",
       "      <td>-0.143708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161444</td>\n",
       "      <td>0.008394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35500 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            permno    return     mom1m    mom12m     chmom    indmom  \\\n",
       "Date                                                                   \n",
       "2001-02-28   13610  0.161318 -0.190508  0.327877  0.249243  0.018187   \n",
       "2001-02-28   13856  0.046940 -0.110820  0.471192 -0.384316  0.115779   \n",
       "2001-02-28   13901  0.094426  0.000000  1.261056  0.535897  0.682048   \n",
       "2001-02-28   13928 -0.084292  0.030857  0.431206 -0.111444  0.682048   \n",
       "2001-02-28   13936  0.149662 -0.006923  0.957347  0.098914 -0.032018   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "2006-12-31   89279  0.048871  0.024940 -0.031547  0.072748  0.098944   \n",
       "2006-12-31   89317 -0.054903  0.098958 -0.275862  0.327413  0.163590   \n",
       "2006-12-31   89456  0.160222 -0.045905  0.019759  0.342970  0.085635   \n",
       "2006-12-31   89790 -0.018619  0.080000 -0.213837 -0.241931  0.068689   \n",
       "2006-12-31   89915 -0.027124  0.166667 -0.035572  0.263321  0.122462   \n",
       "\n",
       "              mom36m      turn         mvel1     dolvol  ...    retvol  \\\n",
       "Date                                                     ...             \n",
       "2001-02-28 -0.285854  1.023598  8.012218e+05  13.974887  ...  0.028112   \n",
       "2001-02-28 -0.027868  0.691164  6.359623e+07  17.810579  ...  0.020727   \n",
       "2001-02-28 -0.446731  0.829092  9.783550e+07  17.863872  ...  0.032157   \n",
       "2001-02-28 -0.021776  0.842627  1.496689e+07  16.501171  ...  0.016428   \n",
       "2001-02-28 -0.421654  0.820512  3.525850e+05  12.565110  ...  0.045878   \n",
       "...              ...       ...           ...        ...  ...       ...   \n",
       "2006-12-31 -0.027805  0.065080  9.697706e+04   9.063220  ...  0.011695   \n",
       "2006-12-31  0.304287  0.025187  1.166978e+05   7.426549  ...  0.016572   \n",
       "2006-12-31  0.545880  1.244986  3.647852e+05  13.235699  ...  0.023065   \n",
       "2006-12-31  0.458716  0.814450  5.602500e+04  10.551278  ...  0.027389   \n",
       "2006-12-31  1.197060  0.672472  7.856415e+05  12.643065  ...  0.026306   \n",
       "\n",
       "             idiovol      beta    betasq        ep        sp       agr  nincr  \\\n",
       "Date                                                                            \n",
       "2001-02-28  0.058059  0.385289  0.148447  0.019041  1.472909  0.325935    5.0   \n",
       "2001-02-28  0.043186  0.118710  0.014092  0.039970  0.397105  0.225463    1.0   \n",
       "2001-02-28  0.050186  0.021928  0.000481  0.142695  1.148088 -0.024383    2.0   \n",
       "2001-02-28  0.038102  0.142332  0.020258  0.051091  1.138525 -0.069288    1.0   \n",
       "2001-02-28  0.068790  1.022686  1.045888  0.091598  6.902488  0.000838    1.0   \n",
       "...              ...       ...       ...       ...       ...       ...    ...   \n",
       "2006-12-31  0.018700  0.115212  0.013274  0.060214  0.254025 -0.042325    0.0   \n",
       "2006-12-31  0.040691  0.271733  0.073839 -0.130443  0.836804 -0.183381    0.0   \n",
       "2006-12-31  0.054782  1.819325  3.309943  0.052840  1.019684  0.011990    0.0   \n",
       "2006-12-31  0.110512  2.490410  6.202142  0.001406  0.353447 -0.066737    1.0   \n",
       "2006-12-31  0.042038  1.130174  1.277294  0.059130  0.394275 -0.143708    0.0   \n",
       "\n",
       "            return(t-1)    r(t+1)  \n",
       "Date                               \n",
       "2001-02-28    -0.202242 -0.009186  \n",
       "2001-02-28    -0.112756 -0.041659  \n",
       "2001-02-28     0.010566  0.002179  \n",
       "2001-02-28     0.033114  0.034813  \n",
       "2001-02-28     0.014335  0.031713  \n",
       "...                 ...       ...  \n",
       "2006-12-31     0.026024 -0.004154  \n",
       "2006-12-31     0.097319 -0.128977  \n",
       "2006-12-31    -0.041839 -0.024223  \n",
       "2006-12-31     0.084549 -0.058698  \n",
       "2006-12-31     0.161444  0.008394  \n",
       "\n",
       "[35500 rows x 23 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows = generate_rolling_windows(df, 19, 6, 4)\n",
    "\n",
    "# to get training sample of the first split:\n",
    "windows[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e4c8fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = windows[0][0].dropna()\n",
    "validation = windows[0][1].dropna()\n",
    "testing = windows[0][2].dropna()\n",
    "training_combined = windows[0][3].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "db135b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_train = training['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6ad3d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_val = validation['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "02da496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test = testing['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "abcac36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = training_combined.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_train_combined = training_combined['r(t+1)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a45c7",
   "metadata": {},
   "source": [
    "# Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b2b01c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters based on the paper\n",
    "depths = range(1, 7)  \n",
    "n_trees = 300         \n",
    "feature_splits = [3, 5, 10, 20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bee5744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_calc(actual, predicted):\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted).flatten()\n",
    "    \n",
    "    predicted = np.clip(predicted, 0, None)\n",
    "    \n",
    "    ss_res = np.sum((actual - predicted) ** 2)\n",
    "    \n",
    "    ss_tot = np.sum(actual ** 2)\n",
    "    \n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "beee4dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 0.011232871152665247\n",
      "1 5 0.012425960639786182\n",
      "1 10 0.013882363673785036\n",
      "1 20 0.014357976541994999\n",
      "2 3 0.016195901271945146\n",
      "2 5 0.017414537733786983\n",
      "2 10 0.019512067119641707\n",
      "2 20 0.019917211521390032\n",
      "3 3 0.0194652238358084\n",
      "3 5 0.021611248892600132\n",
      "3 10 0.02253278765665978\n",
      "3 20 0.022198044375804193\n",
      "4 3 0.02189419987239749\n",
      "4 5 0.021506322456899873\n",
      "4 10 0.022259438461185943\n",
      "4 20 0.023540961133823757\n",
      "5 3 0.022350696414358495\n",
      "5 5 0.023350831444073572\n",
      "5 10 0.022903638673507754\n",
      "5 20 0.023843663108134017\n",
      "6 3 0.024380405193671795\n",
      "6 5 0.022500495844439583\n",
      "6 10 0.02316385450230385\n",
      "6 20 0.022183029686349442\n",
      "Best hyperparameters (max_depth, max_features): (6, 3)\n",
      "Best R^2 OOS: 0.024380405193671795\n"
     ]
    }
   ],
   "source": [
    "roos_vals = {}\n",
    "\n",
    "for max_depth in depths:\n",
    "\n",
    "    for max_features in feature_splits:\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                                   max_depth = max_depth,\n",
    "                                   max_features = max_features,\n",
    "                                   random_state = 42)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        predictions = rf.predict(X_val)\n",
    "\n",
    "        r_val = R_calc(y_val, predictions)\n",
    "\n",
    "        roos_vals[((max_depth, max_features))] = r_val\n",
    "        print(max_depth, max_features, r_val)\n",
    "\n",
    "best_hyperparameters = max(roos_vals, key=roos_vals.get)\n",
    "best_r = roos_vals[best_hyperparameters]\n",
    "\n",
    "print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\n",
    "print(\"Best R^2 OOS:\", best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "afd67041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nroos_vals = {}\\ndepth = best_hyperparameters[0]\\nfeature = best_hyperparameters[1]\\n\\nfor i in range(len(windows)):\\n\\n    training = windows[i][0].dropna()\\n    validation = windows[i][1].dropna()\\n    testing = windows[i][2].dropna()\\n    training_combined = windows[i][3].dropna()\\n    \\n    X_train = training.drop(columns = [\\'permno\\', \\'return\\', \\'r(t+1)\\'])\\n    y_train = training[\\'r(t+1)\\']\\n    \\n    X_val = validation.drop(columns = [\\'permno\\', \\'return\\', \\'r(t+1)\\'])\\n    y_val = validation[\\'r(t+1)\\']\\n    \\n    X_test = testing.drop(columns = [\\'permno\\', \\'return\\', \\'r(t+1)\\'])\\n    y_test = testing[\\'r(t+1)\\']\\n    \\n    X_train_combined = training_combined.drop(columns = [\\'permno\\', \\'return\\', \\'r(t+1)\\'])\\n    y_train_combined = training_combined[\\'r(t+1)\\']\\n\\n    rf = RandomForestRegressor(n_estimators = n_trees,\\n                               max_depth = depth,\\n                               max_features = feature,\\n                               random_state = 42)\\n\\n    rf.fit(X_train_combined, y_train_combined)\\n\\n    predictions = rf.predict(X_val)\\n\\n    r_val = R_calc(y_val, predictions)\\n\\n    roos_vals[(i)] = r_val\\n    print(i, r_val)\\n\\n    #best_hyperparameters = max(roos_vals, key=roos_vals.get)\\n    #best_r = roos_vals[best_hyperparameters]\\n\\n    #print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\\n    #print(\"Best R^2 OOS:\", best_r)\\n'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "roos_vals = {}\n",
    "depth = best_hyperparameters[0]\n",
    "feature = best_hyperparameters[1]\n",
    "\n",
    "for i in range(len(windows)):\n",
    "\n",
    "    training = windows[i][0].dropna()\n",
    "    validation = windows[i][1].dropna()\n",
    "    testing = windows[i][2].dropna()\n",
    "    training_combined = windows[i][3].dropna()\n",
    "    \n",
    "    X_train = training.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_train = training['r(t+1)']\n",
    "    \n",
    "    X_val = validation.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_val = validation['r(t+1)']\n",
    "    \n",
    "    X_test = testing.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_test = testing['r(t+1)']\n",
    "    \n",
    "    X_train_combined = training_combined.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_train_combined = training_combined['r(t+1)']\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                               max_depth = depth,\n",
    "                               max_features = feature,\n",
    "                               random_state = 42)\n",
    "\n",
    "    rf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    predictions = rf.predict(X_val)\n",
    "\n",
    "    r_val = R_calc(y_val, predictions)\n",
    "\n",
    "    roos_vals[(i)] = r_val\n",
    "    print(i, r_val)\n",
    "\n",
    "    #best_hyperparameters = max(roos_vals, key=roos_vals.get)\n",
    "    #best_r = roos_vals[best_hyperparameters]\n",
    "\n",
    "    #print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\n",
    "    #print(\"Best R^2 OOS:\", best_r)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "caede49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08992928116823606\n"
     ]
    }
   ],
   "source": [
    "depth = best_hyperparameters[0]\n",
    "feature = best_hyperparameters[1]\n",
    "rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                                   max_depth = depth,\n",
    "                                   max_features = feature,\n",
    "                                   random_state = 42)\n",
    "        \n",
    "rf.fit(X_train_combined, y_train_combined)\n",
    "        \n",
    "predictions = rf.predict(X_val)\n",
    "        \n",
    "r_val = R_calc(y_val, predictions)\n",
    "        \n",
    "print(r_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "83fc4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007340982707352506\n"
     ]
    }
   ],
   "source": [
    "test_pred = rf.predict(X_test)\n",
    "val = R_calc(y_test, test_pred)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa9944",
   "metadata": {},
   "source": [
    "# Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c3dc5bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    100\n",
       "r(t+1)         100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8433cc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/jvj1v_bx7kldrcbf4gl1ml7m0000gn/T/ipykernel_36063/778819346.py:13: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  validation = data[idx_1:idx_2]\n",
      "/var/folders/6h/jvj1v_bx7kldrcbf4gl1ml7m0000gn/T/ipykernel_36063/778819346.py:14: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  testing = data[idx_2:].dropna()\n"
     ]
    }
   ],
   "source": [
    "windows = generate_rolling_windows(top_100, 19, 6, 4)\n",
    "\n",
    "training = windows[0][0].dropna()\n",
    "validation = windows[0][1].dropna()\n",
    "testing = windows[0][2].dropna()\n",
    "training_combined = windows[0][3].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "10a1d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_train = training['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "62f6d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_val = validation['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8cffd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test = testing['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b9b5d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = training_combined.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_train_combined = training_combined['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3f72a94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 -0.000861724093917271\n",
      "1 5 -0.0013528519368128933\n",
      "1 10 -0.0012850165960602844\n",
      "1 20 -0.0014453063287205303\n",
      "2 3 -0.0006605045583853997\n",
      "2 5 -0.0009320465022950586\n",
      "2 10 -0.0017541836844991998\n",
      "2 20 -0.001883846597476424\n",
      "3 3 -0.00022194811165832107\n",
      "3 5 -0.0007598854200716598\n",
      "3 10 -0.0015595299295763088\n",
      "3 20 -0.0021621480531714976\n",
      "4 3 0.00012513923023471651\n",
      "4 5 0.00016935057953681998\n",
      "4 10 -0.0007160422335297234\n",
      "4 20 -0.0016134036326875822\n",
      "5 3 0.00010828116034022894\n",
      "5 5 -0.000916385533916042\n",
      "5 10 -0.0006904614146558963\n",
      "5 20 -0.0007909864521535859\n",
      "6 3 -5.273112472248265e-05\n",
      "6 5 0.0006098480663929706\n",
      "6 10 0.0003689406098265069\n",
      "6 20 0.0012477258270086056\n",
      "Best hyperparameters (max_depth, max_features): (6, 20)\n",
      "Best R^2 OOS: 0.0012477258270086056\n"
     ]
    }
   ],
   "source": [
    "roos_vals = {}\n",
    "\n",
    "for max_depth in depths:\n",
    "\n",
    "    for max_features in feature_splits:\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                                   max_depth = max_depth,\n",
    "                                   max_features = max_features,\n",
    "                                   random_state = 42)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        predictions = rf.predict(X_val)\n",
    "\n",
    "        r_val = R_calc(y_val, predictions)\n",
    "\n",
    "        roos_vals[((max_depth, max_features))] = r_val\n",
    "        print(max_depth, max_features, r_val)\n",
    "\n",
    "best_hyperparameters = max(roos_vals, key=roos_vals.get)\n",
    "best_r = roos_vals[best_hyperparameters]\n",
    "\n",
    "print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\n",
    "print(\"Best R^2 OOS:\", best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "roos_vals = {}\n",
    "\n",
    "\n",
    "for i in range(len(windows)):\n",
    "\n",
    "    training = windows[i][0].dropna()\n",
    "    validation = windows[i][1].dropna()\n",
    "    testing = windows[i][2].dropna()\n",
    "    training_combined = windows[i][3].dropna()\n",
    "    \n",
    "    X_train = training.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_train = training['r(t+1)']\n",
    "    \n",
    "    X_val = validation.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_val = validation['r(t+1)']\n",
    "    \n",
    "    X_test = testing.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_test = testing['r(t+1)']\n",
    "    \n",
    "    X_train_combined = training_combined.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_train_combined = training_combined['r(t+1)']\n",
    "\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                               max_depth = depth,\n",
    "                               max_features = feature,\n",
    "                               random_state = 42)\n",
    "\n",
    "    rf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    predictions = rf.predict(X_val)\n",
    "\n",
    "    r_val = R_calc(y_val, predictions)\n",
    "\n",
    "    roos_vals[(i)] = r_val\n",
    "    print(i, r_val)\n",
    "\n",
    "    #best_hyperparameters = max(roos_vals, key=roos_vals.get)\n",
    "    #best_r = roos_vals[best_hyperparameters]\n",
    "\n",
    "    #print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\n",
    "    #print(\"Best R^2 OOS:\", best_r)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3fc020e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0559743943218215\n"
     ]
    }
   ],
   "source": [
    "depth = best_hyperparameters[0]\n",
    "feature = best_hyperparameters[1]\n",
    "rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                                   max_depth = depth,\n",
    "                                   max_features = feature,\n",
    "                                   random_state = 42)\n",
    "        \n",
    "rf.fit(X_train_combined, y_train_combined)\n",
    "        \n",
    "predictions = rf.predict(X_val)\n",
    "        \n",
    "r_val = R_calc(y_val, predictions)\n",
    "        \n",
    "print(r_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4fc2d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019976562152977162\n"
     ]
    }
   ],
   "source": [
    "test_pred = rf.predict(X_test)\n",
    "val = R_calc(y_test, test_pred)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f511ca4",
   "metadata": {},
   "source": [
    "# Bottom 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ea5becb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/jvj1v_bx7kldrcbf4gl1ml7m0000gn/T/ipykernel_36063/778819346.py:13: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  validation = data[idx_1:idx_2]\n",
      "/var/folders/6h/jvj1v_bx7kldrcbf4gl1ml7m0000gn/T/ipykernel_36063/778819346.py:14: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  testing = data[idx_2:].dropna()\n"
     ]
    }
   ],
   "source": [
    "windows = generate_rolling_windows(bottom_100, 19, 6, 4)\n",
    "\n",
    "training = windows[0][0].dropna()\n",
    "validation = windows[0][1].dropna()\n",
    "testing = windows[0][2].dropna()\n",
    "training_combined = windows[0][3].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8a2a25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_train = training['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aa581686",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_val = validation['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1e458921",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test = testing['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "53e802bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = training_combined.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_train_combined = training_combined['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cc490cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 0.03147756117830669\n",
      "1 5 0.03367965731601996\n",
      "1 10 0.03455543955720375\n",
      "1 20 0.033253943280103226\n",
      "2 3 0.04066655896404536\n",
      "2 5 0.042781972770092436\n",
      "2 10 0.04148429125725195\n",
      "2 20 0.04212885411245071\n",
      "3 3 0.04193022671334845\n",
      "3 5 0.04808717512952043\n",
      "3 10 0.044589292359935695\n",
      "3 20 0.0442671988198271\n",
      "4 3 0.0483481224954222\n",
      "4 5 0.048920698311961\n",
      "4 10 0.044844204454248304\n",
      "4 20 0.0428427263824831\n",
      "5 3 0.0487136147250099\n",
      "5 5 0.04708616571249491\n",
      "5 10 0.044029259264825704\n",
      "5 20 0.04376178545793452\n",
      "6 3 0.047867112207840457\n",
      "6 5 0.04922239826930841\n",
      "6 10 0.04255178593828335\n",
      "6 20 0.0435411424000679\n",
      "Best hyperparameters (max_depth, max_features): (6, 5)\n",
      "Best R^2 OOS: 0.04922239826930841\n"
     ]
    }
   ],
   "source": [
    "roos_vals = {}\n",
    "\n",
    "for max_depth in depths:\n",
    "\n",
    "    for max_features in feature_splits:\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                                   max_depth = max_depth,\n",
    "                                   max_features = max_features,\n",
    "                                   random_state = 42)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        predictions = rf.predict(X_val)\n",
    "\n",
    "        r_val = R_calc(y_val, predictions)\n",
    "\n",
    "        roos_vals[((max_depth, max_features))] = r_val\n",
    "        print(max_depth, max_features, r_val)\n",
    "\n",
    "best_hyperparameters = max(roos_vals, key=roos_vals.get)\n",
    "best_r = roos_vals[best_hyperparameters]\n",
    "\n",
    "print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\n",
    "print(\"Best R^2 OOS:\", best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04db5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "roos_vals = {}\n",
    "depth = best_hyperparameters[0]\n",
    "feature = best_hyperparameters[1]\n",
    "\n",
    "for i in range(len(windows)):\n",
    "\n",
    "    training = windows[i][0].dropna()\n",
    "    validation = windows[i][1].dropna()\n",
    "    testing = windows[i][2].dropna()\n",
    "    training_combined = windows[i][3].dropna()\n",
    "    \n",
    "    X_train = training.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_train = training['r(t+1)']\n",
    "    \n",
    "    X_val = validation.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_val = validation['r(t+1)']\n",
    "    \n",
    "    X_test = testing.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_test = testing['r(t+1)']\n",
    "    \n",
    "    X_train_combined = training_combined.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "    y_train_combined = training_combined['r(t+1)']\n",
    "\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                               max_depth = depth,\n",
    "                               max_features = feature,\n",
    "                               random_state = 42)\n",
    "\n",
    "    rf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    predictions = rf.predict(X_val)\n",
    "\n",
    "    r_val = R_calc(y_val, predictions)\n",
    "\n",
    "    roos_vals[(i)] = r_val\n",
    "    print(i, r_val)\n",
    "\n",
    "    #best_hyperparameters = max(roos_vals, key=roos_vals.get)\n",
    "    #best_r = roos_vals[best_hyperparameters]\n",
    "\n",
    "    #print(\"Best hyperparameters (max_depth, max_features):\", best_hyperparameters)\n",
    "    #print(\"Best R^2 OOS:\", best_r)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38286189",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = best_hyperparameters[0]\n",
    "feature = best_hyperparameters[1]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = n_trees,\n",
    "                                   max_depth = depth,\n",
    "                                   max_features = feature,\n",
    "                                   random_state = 42)\n",
    "        \n",
    "rf.fit(X_train_combined, y_train_combined)\n",
    "        \n",
    "predictions = rf.predict(X_val)\n",
    "        \n",
    "r_val = R_calc(y_val, predictions)\n",
    "        \n",
    "print(r_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = rf.predict(X_test)\n",
    "val = R_calc(y_test, test_pred)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13ea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
