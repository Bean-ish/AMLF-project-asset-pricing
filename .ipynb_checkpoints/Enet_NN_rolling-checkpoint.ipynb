{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e35d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdfe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/users/LL/Documents/GitHub/AMLF_projects/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9bfc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485ca046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>permno</th>\n",
       "      <th>return</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>chmom</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom36m</th>\n",
       "      <th>turn</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>...</th>\n",
       "      <th>baspread</th>\n",
       "      <th>retvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>ep</th>\n",
       "      <th>sp</th>\n",
       "      <th>agr</th>\n",
       "      <th>nincr</th>\n",
       "      <th>return(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13610</td>\n",
       "      <td>-0.202242</td>\n",
       "      <td>0.277978</td>\n",
       "      <td>-0.082232</td>\n",
       "      <td>0.518490</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>-0.258322</td>\n",
       "      <td>0.820391</td>\n",
       "      <td>9.897840e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>0.398706</td>\n",
       "      <td>0.158967</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>1.472909</td>\n",
       "      <td>0.325935</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13856</td>\n",
       "      <td>-0.112756</td>\n",
       "      <td>0.095372</td>\n",
       "      <td>0.300233</td>\n",
       "      <td>-0.147620</td>\n",
       "      <td>0.069669</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.660636</td>\n",
       "      <td>7.152231e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033983</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.039970</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13901</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.166088</td>\n",
       "      <td>0.759861</td>\n",
       "      <td>0.504130</td>\n",
       "      <td>0.400659</td>\n",
       "      <td>-0.440929</td>\n",
       "      <td>0.775189</td>\n",
       "      <td>9.783550e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>0.050243</td>\n",
       "      <td>0.088382</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>1.148088</td>\n",
       "      <td>-0.024383</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13928</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.039925</td>\n",
       "      <td>0.400659</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>0.813903</td>\n",
       "      <td>1.451888e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>0.159983</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.051091</td>\n",
       "      <td>1.138525</td>\n",
       "      <td>-0.069288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13936</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.574141</td>\n",
       "      <td>0.224657</td>\n",
       "      <td>-0.075486</td>\n",
       "      <td>-0.397110</td>\n",
       "      <td>0.755288</td>\n",
       "      <td>3.550430e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031413</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>1.060490</td>\n",
       "      <td>1.124640</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>6.902488</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  permno    return     mom1m    mom12m     chmom    indmom  \\\n",
       "0  2001-01-31   13610 -0.202242  0.277978 -0.082232  0.518490  0.198455   \n",
       "1  2001-01-31   13856 -0.112756  0.095372  0.300233 -0.147620  0.069669   \n",
       "2  2001-01-31   13901  0.010566  0.166088  0.759861  0.504130  0.400659   \n",
       "3  2001-01-31   13928  0.033114  0.006637  0.236486  0.039925  0.400659   \n",
       "4  2001-01-31   13936  0.014335  0.009709  0.574141  0.224657 -0.075486   \n",
       "\n",
       "     mom36m      turn         mvel1  ...  baspread    retvol   idiovol  \\\n",
       "0 -0.258322  0.820391  9.897840e+05  ...  0.037278  0.032888  0.056769   \n",
       "1  0.000718  0.660636  7.152231e+07  ...  0.033983  0.022389  0.042020   \n",
       "2 -0.440929  0.775189  9.783550e+07  ...  0.032844  0.023475  0.050243   \n",
       "3  0.025686  0.813903  1.451888e+07  ...  0.035964  0.023917  0.037427   \n",
       "4 -0.397110  0.755288  3.550430e+05  ...  0.031413  0.030343  0.068491   \n",
       "\n",
       "       beta    betasq        ep        sp       agr  nincr  return(t-1)  \n",
       "0  0.398706  0.158967  0.019041  1.472909  0.325935    5.0          NaN  \n",
       "1  0.106574  0.011358  0.039970  0.397105  0.225463    1.0          NaN  \n",
       "2  0.088382  0.007811  0.142695  1.148088 -0.024383    2.0          NaN  \n",
       "3  0.159983  0.025595  0.051091  1.138525 -0.069288    1.0          NaN  \n",
       "4  1.060490  1.124640  0.091598  6.902488  0.000838    0.0          NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0fa84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Index(['Date', 'permno', 'return', 'mom1m', 'mom12m', 'chmom', 'indmom',\n",
      "       'mom36m', 'turn', 'mvel1', 'dolvol', 'ill', 'zerotrade', 'baspread',\n",
      "       'retvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr',\n",
      "       'return(t-1)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46799c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         12.968131\n",
       "1         17.527472\n",
       "2         17.773933\n",
       "3         16.111030\n",
       "4         12.518458\n",
       "            ...    \n",
       "113995    10.203254\n",
       "113996     9.558279\n",
       "113997    11.116588\n",
       "113998    14.259460\n",
       "113999    14.433653\n",
       "Name: dolvol, Length: 114000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dolvol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cccd2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            object\n",
       "permno           int64\n",
       "return         float64\n",
       "mom1m          float64\n",
       "mom12m         float64\n",
       "chmom          float64\n",
       "indmom         float64\n",
       "mom36m         float64\n",
       "turn           float64\n",
       "mvel1          float64\n",
       "dolvol         float64\n",
       "ill            float64\n",
       "zerotrade      float64\n",
       "baspread       float64\n",
       "retvol         float64\n",
       "idiovol        float64\n",
       "beta           float64\n",
       "betasq         float64\n",
       "ep             float64\n",
       "sp             float64\n",
       "agr            float64\n",
       "nincr          float64\n",
       "return(t-1)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64903994",
   "metadata": {},
   "source": [
    "According to note 30: \"Therefore, to predict returns at month t+1, we use most recent monthly characteristics at the end of month t.\" <br>\n",
    "Hence, **shift return t+1 to serve as response: r(t+1)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r(t+1)'] = df.groupby('permno')['return'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a1d5769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1521d1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "permno            0\n",
       "return            0\n",
       "mom1m             3\n",
       "mom12m          269\n",
       "chmom           269\n",
       "indmom            0\n",
       "mom36m         1566\n",
       "turn              9\n",
       "mvel1             0\n",
       "dolvol            6\n",
       "ill               0\n",
       "zerotrade         0\n",
       "baspread          0\n",
       "retvol            0\n",
       "idiovol         352\n",
       "beta            352\n",
       "betasq          352\n",
       "ep              473\n",
       "sp              473\n",
       "agr            1026\n",
       "nincr          2794\n",
       "return(t-1)     500\n",
       "r(t+1)          500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110f651",
   "metadata": {},
   "source": [
    "### handle missing data\n",
    "\n",
    "According to note 30 (bottom of p 2248): \"Another issue is missing characteristics, which we replace with the cross-sectional median at each month for each stock, respectively.\" <br>\n",
    "Hence, calculate monthly cross-sectional median for features: **'mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581efc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.copy()\n",
    "for feature in ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']:\n",
    "    df_filled[feature] = df_filled.groupby('Date')[feature].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8094662b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d22efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']] = df_filled.loc[:,['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9379e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4352d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the datetime column as index\n",
    "df.set_index('Date', inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b1f46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8f4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "permno = df['permno'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "822df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['permno'] = permno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a730d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e5993c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_2 = df_scaled.drop(columns = [ 'permno', 'return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cea22",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad622f5c",
   "metadata": {},
   "source": [
    "**split training, validation, and testing datasets**\n",
    "\n",
    "training : validation : testing = 6 yr : 4yr : 9 yr <br>\n",
    "Also drop the first and last month due to the absence of r(t+1) and return(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c7915c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = df_scaled[:'2007-01-01'].dropna()\n",
    "# validation = df_scaled['2007-01-01':'2011-01-01']\n",
    "# testing = df_scaled['2011-01-01':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd1f3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_combined = df_scaled[:'2011-01-01'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613068a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd311e5b",
   "metadata": {},
   "source": [
    "**separate X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef894e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = training.drop(columns = ['r(t+1)'])\n",
    "# y_train = training['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "513ee4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = validation.drop(columns = ['r(t+1)'])\n",
    "# y_val = validation['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b557f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = testing.drop(columns = ['r(t+1)'])\n",
    "# y_test = testing['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b683b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_combined = training_combined.drop(columns = ['r(t+1)'])\n",
    "# y_train_combined = training_combined['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5127d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.isna().values.sum())\n",
    "# print(X_val.isna().values.sum())\n",
    "# print(X_test.isna().values.sum())\n",
    "# print(y_train.isna().values.sum())\n",
    "# print(y_val.isna().values.sum())\n",
    "# print(y_test.isna().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15eb2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training.shape)\n",
    "# print(validation.shape)\n",
    "# print(testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4ab11",
   "metadata": {},
   "source": [
    "### generate rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0946f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rolling_windows(data, total_years, initial_train_size, val_size):\n",
    "    total_years = total_years\n",
    "    windows = []\n",
    "    initial_train_size = initial_train_size\n",
    "    val_size = val_size\n",
    "\n",
    "    # Loop through the years to create rolling windows\n",
    "    for i in range(initial_train_size + 1, total_years-val_size):\n",
    "        idx_1 = '20' + str(i).zfill(2) + '-01-01'\n",
    "        idx_2 = '20' + str(i + val_size).zfill(2) + '-01-01'\n",
    "        \n",
    "        training = data[:idx_1].dropna()\n",
    "        validation = data[idx_1:idx_2]\n",
    "        testing = data[idx_2:].dropna()\n",
    "        \n",
    "        train_com = data[:idx_2].dropna()\n",
    "\n",
    "        windows.append((training, validation, testing, train_com))\n",
    "        \n",
    "    return windows\n",
    "\n",
    "\n",
    "# for inital split: training, validation, testing, train_combined \n",
    "#                       - windows[0][0], windows[0][1], windows[0][2], windows[0][3]\n",
    "\n",
    "# increase the first index by 1 using for loop to fit all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5a4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling samples\n",
    "\n",
    "windows = generate_rolling_windows(df_scaled_2, 19, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39a02f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2beec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bab15222",
   "metadata": {},
   "source": [
    "### subsetting data: top and bottom 100 stocks on market value (mvel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e27b0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0756555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvel_sorted_top = subset['2019-12-01':].sort_values('mvel1',ascending=False).head(100).reset_index(drop=True)\n",
    "filter_values_top = mvel_sorted_top['permno']\n",
    "top_100 = subset[subset['permno'].isin(filter_values_top)]\n",
    "\n",
    "\n",
    "mvel_sorted_bot = subset['2019-12-01':].sort_values('mvel1',ascending=False).tail(100).reset_index(drop=True)\n",
    "filter_values_bot = mvel_sorted_bot['permno']\n",
    "bot_100 = subset[subset['permno'].isin(filter_values_bot)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8ff898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22800, 23)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100.shape\n",
    "# 19*12*10 = 2280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9305903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c03273f",
   "metadata": {},
   "source": [
    "**splitting data & separating X and y** <br>\n",
    "***\n",
    "splitting data 10:9 years - to make the training set the same size as the training and validation set combined, leave testing set out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb14aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_top = top_100[:'2011-01-01'].dropna()\n",
    "testing_top = top_100['2011-01-02':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "482d1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bot = bot_100[:'2011-01-01'].dropna()\n",
    "testing_bot = bot_100['2011-01-02':].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e2063",
   "metadata": {},
   "source": [
    "separating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a29d3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_top = testing_top.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test_top = testing_top['r(t+1)']\n",
    "\n",
    "X_test_bot = testing_bot.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test_bot = testing_bot['r(t+1)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8b1b0",
   "metadata": {},
   "source": [
    "## packages & custom funcs\n",
    "***\n",
    "1. R^2 without demeaning\n",
    "2. tuning_1: fixed set hyperparameter tuning\n",
    "3. tuning: recursive rolling tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a0a667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce231db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r^2-oos for Enet\n",
    "\n",
    "def r2_score_wo_demeaning(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    ss_res = 0\n",
    "    ss_tot = 0\n",
    "    for i in range(len(y_true)):\n",
    "        ss_res = ss_res + ((y_true[i] - y_pred[i])**2)\n",
    "        ss_tot = ss_tot + ((y_true[i] - 0)**2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return float(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1557d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_1 (model, param_combos, X_train, y_train, X_val, y_val):\n",
    "#   param_combos: list of dictionaries of parameters combo\n",
    "    \n",
    "    results = {'param': [], 'score': []}\n",
    "    opt_param = 0\n",
    "    opt_score = 0\n",
    "\n",
    "    for params in param_combos:\n",
    "\n",
    "        for param_name, param_value in params.items():\n",
    "            setattr(model, param_name, param_value)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "#         print(\"Shape of y_val:\", y_val.shape)\n",
    "#         print(\"Shape of y_pred:\", y_pred.shape)\n",
    "        \n",
    "        r2 = r2_score_wo_demeaning(y_val, y_pred)\n",
    "\n",
    "        results['param'].append(params)\n",
    "        results['score'].append(r2)\n",
    "    \n",
    "    sorted_zipped = sorted(zip(results['param'], results['score']), key=lambda x: x[1])\n",
    "    opt_param = sorted_zipped[0][0]\n",
    "    opt_score = sorted_zipped[0][1]\n",
    "    \n",
    "    return opt_param, opt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35d57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e918c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9682d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e3ce901",
   "metadata": {},
   "source": [
    "## Enet\n",
    "\n",
    "\n",
    "prediction: g*(z i,t) - depends on neither i nor t, is dependend on z only through z i,t <br>\n",
    "responses: r i, t+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf763cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d566281",
   "metadata": {},
   "source": [
    "**tuning**\n",
    "\n",
    "1. set-up the search grid\n",
    "2. tuning: recursive rolling validation set w/ oos R^2 metric -- <br>\n",
    "    roll one unit froward each time and take the average as the final score <br>\n",
    "3. pick the best hyperparameters, retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62b1cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up searching grid\n",
    "\n",
    "alpha_values = [0.4, 0.5, 0.6]\n",
    "l1_ratio_values = np.logspace(-4, -1, 10)\n",
    "\n",
    "param_enet = [{'alpha': alpha, 'l1_ratio': l1_ratio} for alpha in alpha_values for l1_ratio in l1_ratio_values]\n",
    "\n",
    "# for param_combination in param_combinations:\n",
    "#     print(param_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "027fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "\n",
    "Enet = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d6424ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is 0.0007755796797865866.\n",
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is 0.002077004617268674.\n",
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is -0.0014524607777255394.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0063834100482236256.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.004957498963627627.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0035499187056395876.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0012202180037492738.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0022601722569968175.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for window in windows:\n",
    "    \n",
    "    #apply tuning function\n",
    "    result = tuning_1(Enet, param_enet, window[0].drop(columns = ['r(t+1)']), window[0]['r(t+1)'], window[1].drop(columns = ['r(t+1)']), window[1]['r(t+1)'])\n",
    "    \n",
    "    # print out tuning parameters of eah]ch split\n",
    "    print(f\"the optimal parameters are {result[0]} and the best score is {result[1]}.\")\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "779c0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for window in windows:\n",
    "#     print(window[0].drop(columns = ['r(t+1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bedc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f2c02ec",
   "metadata": {},
   "source": [
    "**best model** <br>\n",
    "<br>\n",
    "Fit on all data in training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d106cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Enet_opt = ElasticNet()\n",
    "r2_Enet = []\n",
    "r2_Enet_top = []\n",
    "r2_Enet_bot = []\n",
    "for i in range(8):\n",
    "    \n",
    "    for param_name, param_value in results[i][0].items():\n",
    "     setattr(Enet_opt, param_name, param_value)\n",
    "    \n",
    "    Enet_opt.fit(windows[i][3].drop(columns = ['r(t+1)']), windows[i][3]['r(t+1)'])\n",
    "    y_pred_enet = Enet_opt.predict(windows[i][2].drop(columns = ['r(t+1)']))\n",
    "    \n",
    "    r2_enet = r2_score_wo_demeaning(windows[i][2]['r(t+1)'], y_pred_enet)\n",
    "    r2_Enet.append(r2_enet)       # fit best model for each split\n",
    "    \n",
    "    # used model to generate prediction for the top 100\n",
    "    y_pred_enet_top = Enet_opt.predict(X_test_top)\n",
    "    r2_enet_top = r2_score_wo_demeaning(y_test_top, y_pred_enet_top)\n",
    "    r2_Enet_top.append(r2_enet_top)\n",
    "    \n",
    "    y_pred_enet_bot = Enet_opt.predict(X_test_bot)\n",
    "    r2_enet_bot = r2_score_wo_demeaning(y_test_bot, y_pred_enet_bot)\n",
    "    r2_Enet_bot.append(r2_enet_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ecffeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005663579684225262,\n",
       " 0.0007243052297416508,\n",
       " 0.00015885305985385845,\n",
       " -0.001960710816258926,\n",
       " -0.0008903639645345685,\n",
       " 2.6038543099682343e-05,\n",
       " -0.002316165787667135,\n",
       " -0.00016025654555895663]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the best r^2-oos for 8 splits stored in one list:\n",
    "\n",
    "r2_Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e15f001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2-oos: -0.0004814927891127335\n"
     ]
    }
   ],
   "source": [
    "#take average\n",
    "\n",
    "print(\"R^2-oos:\", sum(r2_Enet) / len(r2_Enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091852f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71740d28",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cb7d04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0026816164329585,\n",
       " 0.0032536355833986397,\n",
       " 0.0033384827679580065,\n",
       " -0.014004771665988347,\n",
       " -0.013416054442168646,\n",
       " -0.017310167694035927,\n",
       " -0.011820903699103269,\n",
       " -0.008782282295214605]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_Enet_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c324fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 stocks R^2-oos: -0.007007555626524456\n"
     ]
    }
   ],
   "source": [
    "# take average\n",
    "\n",
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_Enet_top) / len(r2_Enet_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05f088ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.002231535569684029,\n",
       " -0.0009302732914853173,\n",
       " -0.0010422973876647035,\n",
       " -0.005407781758678176,\n",
       " -0.004479592866621029,\n",
       " -0.002450936187006425,\n",
       " -0.0032335221090211697,\n",
       " -0.0031839051781878958]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_Enet_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e12d2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 100 stocks R^2-oos: -0.0028699805435435932\n"
     ]
    }
   ],
   "source": [
    "# take average\n",
    "\n",
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_Enet_bot) / len(r2_Enet_bot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77969a4c",
   "metadata": {},
   "source": [
    "**feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# coefficients = Enet_opt.coef_\n",
    "\n",
    "# # Get feature names\n",
    "# # Assuming feature_names is a list of your feature names\n",
    "# feature_names = X_train_combined.columns  # Insert your feature names here\n",
    "\n",
    "# # Create a dictionary to store feature importance scores with feature names\n",
    "# feature_importance_dict = dict(zip(feature_names, np.abs(coefficients)))\n",
    "\n",
    "# # Sort feature importance dictionary by importance score\n",
    "# sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Extract feature names and importance scores after sorting\n",
    "# sorted_feature_names = [x[0] for x in sorted_feature_importance]\n",
    "# sorted_feature_importance_scores = [x[1] for x in sorted_feature_importance]\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.barh(sorted_feature_names, sorted_feature_importance_scores)\n",
    "# plt.xlabel('Feature Importance')\n",
    "# plt.ylabel('Features')\n",
    "# plt.title('Feature Importance of Elastic Net Model')\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to have the most important features at the top\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2054aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f12888",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ca69c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c328bf",
   "metadata": {},
   "source": [
    "**loss function**\n",
    "\n",
    "Customize the loss function to be **\"penalized cross-sectional average prediction error\" (appendix B.3) aggregated over time**, which is the same as **penalized l2 objective function of prediction errors (p2244)**. <br>\n",
    "***\n",
    "penalty term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13872e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_pcape (y_true, y_pred):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e9b7d",
   "metadata": {},
   "source": [
    "**performance metric**\n",
    "\n",
    "Out-of-sample R^2. (r2_score_wo_demeaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35e44da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def r2_score_wo_demeaning_nn(y_true, y_pred):\n",
    "    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    ss_tot = tf.reduce_sum(tf.square(y_true - 0))\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599f72c",
   "metadata": {},
   "source": [
    "**tuning custom function for neural net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32b3c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_and_tune_model(model, parameter_dicts, x_train, y_train, x_val, y_val):\n",
    "    results = []\n",
    "    \n",
    "    for params in parameter_dicts:\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "                      loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)  # Using mean absolute error (mae) as metric\n",
    "        \n",
    "        history = model.fit(x_train, y_train, epochs=params['epoch'], batch_size=params['batch_size'],\n",
    "                            validation_data=(x_val, y_val), verbose=0)\n",
    "        \n",
    "        # Get the metric value for the last epoch\n",
    "        last_epoch_metric = history.history['r2_score_wo_demeaning_nn'][-1]  # Validation MAE for last epoch\n",
    "        \n",
    "        # Store results for current parameter set\n",
    "        results.append({'params': params, 'val_r2_score_wo_demeaning_nn': last_epoch_metric})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d6471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d292e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f85419",
   "metadata": {},
   "source": [
    "### model\n",
    "\n",
    "All activation functions are ReLU function <br>\n",
    "optimizer: SGD w/ learning rate shrinkage: adam <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0ff5a",
   "metadata": {},
   "source": [
    "convert dataframes to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a6931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a4b2d0",
   "metadata": {},
   "source": [
    "set-up grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72655500",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch_val = [25, 50, 75, 100]\n",
    "lr_val = [0.05, 0.025, 0.01]\n",
    "nbatch_val = [1000, 1500, 3000]\n",
    "\n",
    "param_nn = [{'epoch': epoch, 'learning_rate': learning_rate, 'batch_size': batch_size} for epoch in nepoch_val for learning_rate in lr_val for batch_size in nbatch_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1f391",
   "metadata": {},
   "source": [
    "**1-layer** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4beffabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = 20\n",
    "layer1_n = 32\n",
    "\n",
    "model_1 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc86773",
   "metadata": {},
   "source": [
    "tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24f097c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running\n",
      "finished\n",
      "opt_score:  0.030491596087813377\n",
      "opt_result:  {'epoch': 75, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.02640530839562416\n",
      "opt_result:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.021786686033010483\n",
      "opt_result:  {'epoch': 100, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.04627640172839165\n",
      "opt_result:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.041678592562675476\n",
      "opt_result:  {'epoch': 50, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.03884220868349075\n",
      "opt_result:  {'epoch': 50, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.03660942241549492\n",
      "opt_result:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished\n",
      "opt_score:  0.0348481610417366\n",
      "opt_result:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n"
     ]
    }
   ],
   "source": [
    "results_nn1 = []\n",
    "opt_scores_nn1 = []\n",
    "opt_paras_nn1 = []\n",
    "\n",
    "for window in windows:\n",
    "    print(\"start running\")\n",
    "    # to arry\n",
    "    X_train_nn = np.asarray(window[0].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_nn = np.asarray(window[0]['r(t+1)'].values)\n",
    "\n",
    "    X_val_nn = np.asarray(window[1].drop(columns = ['r(t+1)']).values)\n",
    "    y_val_nn = np.asarray(window[1]['r(t+1)'].values)\n",
    "    \n",
    "    # apply function\n",
    "    result_nn1 = compile_and_tune_model(model_1, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n",
    "    \n",
    "    # get score\n",
    "    result_nn1 = pd.DataFrame(result_nn1).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "    print('finished')\n",
    "    opt_score = result_nn1.iloc[0,1]\n",
    "    print(\"opt_score: \", opt_score)\n",
    "    opt_para = result_nn1.iloc[0,0]\n",
    "    print(\"opt_result: \", opt_para)\n",
    "    # results_nn1.append(result_nn1.iloc[0,])\n",
    "    opt_scores_nn1.append(opt_score)\n",
    "    opt_paras_nn1.append(opt_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b2c540d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>val_r2_score_wo_demeaning_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.034848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.034680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.01, 'batch_s...</td>\n",
       "      <td>0.034348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.034133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.033955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.01, 'batch_s...</td>\n",
       "      <td>0.033724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.033336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.033214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.033107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.025, 'batch_...</td>\n",
       "      <td>0.032542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.032506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.032417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.032317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.031929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.031686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.031576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.031437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.031253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.01, 'batch_s...</td>\n",
       "      <td>0.031251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.031045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.025, 'batch_...</td>\n",
       "      <td>0.030764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.030431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.025, 'batch_...</td>\n",
       "      <td>0.030402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.05, 'batch_s...</td>\n",
       "      <td>0.030133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.029330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.029247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.05, 'batch_s...</td>\n",
       "      <td>0.028524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.028026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.027751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.025677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.025498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.024356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.024209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.05, 'batch_s...</td>\n",
       "      <td>0.023404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.020660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  \\\n",
       "8   {'epoch': 25, 'learning_rate': 0.01, 'batch_si...   \n",
       "17  {'epoch': 50, 'learning_rate': 0.01, 'batch_si...   \n",
       "35  {'epoch': 100, 'learning_rate': 0.01, 'batch_s...   \n",
       "26  {'epoch': 75, 'learning_rate': 0.01, 'batch_si...   \n",
       "23  {'epoch': 75, 'learning_rate': 0.025, 'batch_s...   \n",
       "34  {'epoch': 100, 'learning_rate': 0.01, 'batch_s...   \n",
       "16  {'epoch': 50, 'learning_rate': 0.01, 'batch_si...   \n",
       "7   {'epoch': 25, 'learning_rate': 0.01, 'batch_si...   \n",
       "25  {'epoch': 75, 'learning_rate': 0.01, 'batch_si...   \n",
       "32  {'epoch': 100, 'learning_rate': 0.025, 'batch_...   \n",
       "5   {'epoch': 25, 'learning_rate': 0.025, 'batch_s...   \n",
       "22  {'epoch': 75, 'learning_rate': 0.025, 'batch_s...   \n",
       "6   {'epoch': 25, 'learning_rate': 0.01, 'batch_si...   \n",
       "2   {'epoch': 25, 'learning_rate': 0.05, 'batch_si...   \n",
       "11  {'epoch': 50, 'learning_rate': 0.05, 'batch_si...   \n",
       "24  {'epoch': 75, 'learning_rate': 0.01, 'batch_si...   \n",
       "15  {'epoch': 50, 'learning_rate': 0.01, 'batch_si...   \n",
       "20  {'epoch': 75, 'learning_rate': 0.05, 'batch_si...   \n",
       "33  {'epoch': 100, 'learning_rate': 0.01, 'batch_s...   \n",
       "13  {'epoch': 50, 'learning_rate': 0.025, 'batch_s...   \n",
       "30  {'epoch': 100, 'learning_rate': 0.025, 'batch_...   \n",
       "14  {'epoch': 50, 'learning_rate': 0.025, 'batch_s...   \n",
       "31  {'epoch': 100, 'learning_rate': 0.025, 'batch_...   \n",
       "29  {'epoch': 100, 'learning_rate': 0.05, 'batch_s...   \n",
       "4   {'epoch': 25, 'learning_rate': 0.025, 'batch_s...   \n",
       "12  {'epoch': 50, 'learning_rate': 0.025, 'batch_s...   \n",
       "28  {'epoch': 100, 'learning_rate': 0.05, 'batch_s...   \n",
       "21  {'epoch': 75, 'learning_rate': 0.025, 'batch_s...   \n",
       "19  {'epoch': 75, 'learning_rate': 0.05, 'batch_si...   \n",
       "3   {'epoch': 25, 'learning_rate': 0.025, 'batch_s...   \n",
       "1   {'epoch': 25, 'learning_rate': 0.05, 'batch_si...   \n",
       "18  {'epoch': 75, 'learning_rate': 0.05, 'batch_si...   \n",
       "10  {'epoch': 50, 'learning_rate': 0.05, 'batch_si...   \n",
       "0   {'epoch': 25, 'learning_rate': 0.05, 'batch_si...   \n",
       "27  {'epoch': 100, 'learning_rate': 0.05, 'batch_s...   \n",
       "9   {'epoch': 50, 'learning_rate': 0.05, 'batch_si...   \n",
       "\n",
       "    val_r2_score_wo_demeaning_nn  \n",
       "8                       0.034848  \n",
       "17                      0.034680  \n",
       "35                      0.034348  \n",
       "26                      0.034133  \n",
       "23                      0.033955  \n",
       "34                      0.033724  \n",
       "16                      0.033336  \n",
       "7                       0.033214  \n",
       "25                      0.033107  \n",
       "32                      0.032542  \n",
       "5                       0.032506  \n",
       "22                      0.032417  \n",
       "6                       0.032317  \n",
       "2                       0.031929  \n",
       "11                      0.031686  \n",
       "24                      0.031576  \n",
       "15                      0.031437  \n",
       "20                      0.031253  \n",
       "33                      0.031251  \n",
       "13                      0.031045  \n",
       "30                      0.030764  \n",
       "14                      0.030431  \n",
       "31                      0.030402  \n",
       "29                      0.030133  \n",
       "4                       0.029330  \n",
       "12                      0.029247  \n",
       "28                      0.028524  \n",
       "21                      0.028026  \n",
       "19                      0.027751  \n",
       "3                       0.027600  \n",
       "1                       0.025677  \n",
       "18                      0.025498  \n",
       "10                      0.024356  \n",
       "0                       0.024209  \n",
       "27                      0.023404  \n",
       "9                       0.020660  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcdc47",
   "metadata": {},
   "source": [
    "best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c72a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aba3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn1.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b687a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn1.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d40fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.03335870802402496\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.09111201763153076\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  -0.026174426078796387\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.031564392149448395\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.07620644569396973\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  -0.015497922897338867\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.03095974214375019\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.08349168300628662\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  -0.013969063758850098\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.031458716839551926\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.03973591327667236\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  -0.01545250415802002\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.04084852337837219\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.029665589332580566\n",
      "335/335 [==============================] - 1s 3ms/step\n",
      "bot best score:  -0.02376711368560791\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.03478659689426422\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.09984898567199707\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  -0.008506417274475098\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.01993107795715332\n",
      "335/335 [==============================] - 1s 3ms/step\n",
      "top best score:  -0.011535048484802246\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  0.00767594575881958\n",
      "start fitting\n",
      "finished fitting\n",
      "best score:  -0.03461456298828125\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best score:  -0.0009429454803466797\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best score:  -0.0010194778442382812\n"
     ]
    }
   ],
   "source": [
    "model_nn1 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "last_epoch_metrics = []\n",
    "r2_nn1_tops = []\n",
    "r2_nn1_bots = []\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    model_nn1.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "    X_train_combined_nn = np.asarray(windows[i][3].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_combined_nn = np.asarray(windows[i][3]['r(t+1)'].values)\n",
    "    \n",
    "    X_test_nn = np.asarray(windows[i][2].drop(columns = ['r(t+1)']).values)\n",
    "    y_test_nn = np.asarray(windows[i][2]['r(t+1)'].values)\n",
    "    \n",
    "    # fit the model\n",
    "    print('start fitting')\n",
    "    history = model_nn1.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_paras_nn1[i]['epoch'], batch_size=opt_paras_nn1[i]['batch_size'],\n",
    "                                validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "    print('finished fitting')\n",
    "    \n",
    "    # get scores\n",
    "    last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "    last_epoch_metrics.append(last_epoch_metric)\n",
    "    print('best score: ', last_epoch_metric)\n",
    "    \n",
    "    # top 100\n",
    "    y_pred_nn1_top = model_nn1.predict(X_test_top)\n",
    "    r2_nn1_top = r2_score_wo_demeaning(y_test_top, y_pred_nn1_top)\n",
    "    r2_nn1_tops.append(r2_nn1_top)\n",
    "    print('top best score: ', r2_nn1_top)\n",
    "    \n",
    "    # bot 100\n",
    "    y_pred_nn1_bot = model_nn1.predict(X_test_bot)\n",
    "    r2_nn1_bot = r2_score_wo_demeaning(y_test_bot, y_pred_nn1_bot)\n",
    "    r2_nn1_bots.append(r2_nn1_bot)\n",
    "    print('bot best score: ', r2_nn1_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bfa2bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03335870802402496,\n",
       " -0.031564392149448395,\n",
       " -0.03095974214375019,\n",
       " -0.031458716839551926,\n",
       " -0.04084852337837219,\n",
       " -0.03478659689426422,\n",
       " -0.01993107795715332,\n",
       " -0.03461456298828125]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "230b85cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1 average R^2-oos: -0.03219029004685581\n"
     ]
    }
   ],
   "source": [
    "print(\"NN1 average R^2-oos:\", sum(last_epoch_metrics) / len(last_epoch_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f2aeb",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3259fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.09111201763153076,\n",
       " -0.07620644569396973,\n",
       " -0.08349168300628662,\n",
       " -0.03973591327667236,\n",
       " -0.029665589332580566,\n",
       " -0.09984898567199707,\n",
       " -0.011535048484802246,\n",
       " -0.0009429454803466797]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_nn1_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f893d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.026174426078796387,\n",
       " -0.015497922897338867,\n",
       " -0.013969063758850098,\n",
       " -0.01545250415802002,\n",
       " -0.02376711368560791,\n",
       " -0.008506417274475098,\n",
       " 0.00767594575881958,\n",
       " -0.0010194778442382812]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_nn1_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acfd4105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 stocks R^2-oos: -0.054067328572273254\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_nn1_tops) / len(r2_nn1_tops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0c87e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 100 stocks R^2-oos: -0.012088872492313385\n"
     ]
    }
   ],
   "source": [
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_nn1_bots) / len(r2_nn1_bots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968300d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db3d8800",
   "metadata": {},
   "source": [
    "**3-layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d05b81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = 20\n",
    "layer1_n = 32\n",
    "layer2_n = 16\n",
    "layer3_n = 8\n",
    "\n",
    "\n",
    "model_3 = Sequential([\n",
    "            layers.Dense(layer1_n, input_dim = input_dim, activation='relu'),\n",
    "            layers.Dense(layer2_n, activation='relu'),\n",
    "            layers.Dense(layer3_n, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a2cd7",
   "metadata": {},
   "source": [
    "tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21ef7dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running\n",
      "finished running\n",
      "opt_score:  0.0020256787538528442\n",
      "opt_para:  {'epoch': 50, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.00038105249404907227\n",
      "opt_para:  {'epoch': 75, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.00035774335265159607\n",
      "opt_para:  {'epoch': 100, 'learning_rate': 0.01, 'batch_size': 1500}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.00012042456364724785\n",
      "opt_para:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.0003722429391928017\n",
      "opt_para:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.0002454031491652131\n",
      "opt_para:  {'epoch': 75, 'learning_rate': 0.025, 'batch_size': 3000}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.00023148830223362893\n",
      "opt_para:  {'epoch': 50, 'learning_rate': 0.01, 'batch_size': 1500}\n",
      "start running\n",
      "finished running\n",
      "opt_score:  0.00038271225639618933\n",
      "opt_para:  {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}\n"
     ]
    }
   ],
   "source": [
    "results_nn3 = []\n",
    "opt_scores_nn3 = []\n",
    "opt_paras_nn3 = []\n",
    "\n",
    "for window in windows:\n",
    "    print('start running')\n",
    "    # to arry\n",
    "    X_train_nn = np.asarray(window[0].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_nn = np.asarray(window[0]['r(t+1)'].values)\n",
    "\n",
    "    X_val_nn = np.asarray(window[1].drop(columns = ['r(t+1)']).values)\n",
    "    y_val_nn = np.asarray(window[1]['r(t+1)'].values)\n",
    "\n",
    "    result_nn3 = compile_and_tune_model(model_3, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n",
    "    print('finished running')\n",
    "    \n",
    "    # get score\n",
    "    result_nn3 = pd.DataFrame(result_nn3).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "    opt_score = result_nn3.iloc[0,1]\n",
    "    print('opt_score: ', opt_score)\n",
    "    opt_para = result_nn3.iloc[0,0]\n",
    "    print('opt_para: ', opt_para)\n",
    "    # results_nn1.append(result_nn1.iloc[0,])\n",
    "    opt_scores_nn3.append(opt_score)\n",
    "    opt_paras_nn3.append(opt_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a24cc5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>val_r2_score_wo_demeaning_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.05, 'batch_s...</td>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.01, 'batch_s...</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.01, 'batch_s...</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.01, 'batch_s...</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.01, 'batch_si...</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.025, 'batch_...</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.05, 'batch_s...</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.05, 'batch_s...</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>-0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>-0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'epoch': 75, 'learning_rate': 0.025, 'batch_s...</td>\n",
       "      <td>-0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.025, 'batch_...</td>\n",
       "      <td>-0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'epoch': 100, 'learning_rate': 0.025, 'batch_...</td>\n",
       "      <td>-0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'epoch': 25, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>-0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'epoch': 50, 'learning_rate': 0.05, 'batch_si...</td>\n",
       "      <td>-0.000713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  \\\n",
       "8   {'epoch': 25, 'learning_rate': 0.01, 'batch_si...   \n",
       "14  {'epoch': 50, 'learning_rate': 0.025, 'batch_s...   \n",
       "26  {'epoch': 75, 'learning_rate': 0.01, 'batch_si...   \n",
       "29  {'epoch': 100, 'learning_rate': 0.05, 'batch_s...   \n",
       "5   {'epoch': 25, 'learning_rate': 0.025, 'batch_s...   \n",
       "17  {'epoch': 50, 'learning_rate': 0.01, 'batch_si...   \n",
       "24  {'epoch': 75, 'learning_rate': 0.01, 'batch_si...   \n",
       "6   {'epoch': 25, 'learning_rate': 0.01, 'batch_si...   \n",
       "33  {'epoch': 100, 'learning_rate': 0.01, 'batch_s...   \n",
       "34  {'epoch': 100, 'learning_rate': 0.01, 'batch_s...   \n",
       "35  {'epoch': 100, 'learning_rate': 0.01, 'batch_s...   \n",
       "25  {'epoch': 75, 'learning_rate': 0.01, 'batch_si...   \n",
       "19  {'epoch': 75, 'learning_rate': 0.05, 'batch_si...   \n",
       "16  {'epoch': 50, 'learning_rate': 0.01, 'batch_si...   \n",
       "11  {'epoch': 50, 'learning_rate': 0.05, 'batch_si...   \n",
       "7   {'epoch': 25, 'learning_rate': 0.01, 'batch_si...   \n",
       "23  {'epoch': 75, 'learning_rate': 0.025, 'batch_s...   \n",
       "4   {'epoch': 25, 'learning_rate': 0.025, 'batch_s...   \n",
       "15  {'epoch': 50, 'learning_rate': 0.01, 'batch_si...   \n",
       "32  {'epoch': 100, 'learning_rate': 0.025, 'batch_...   \n",
       "3   {'epoch': 25, 'learning_rate': 0.025, 'batch_s...   \n",
       "28  {'epoch': 100, 'learning_rate': 0.05, 'batch_s...   \n",
       "10  {'epoch': 50, 'learning_rate': 0.05, 'batch_si...   \n",
       "21  {'epoch': 75, 'learning_rate': 0.025, 'batch_s...   \n",
       "18  {'epoch': 75, 'learning_rate': 0.05, 'batch_si...   \n",
       "20  {'epoch': 75, 'learning_rate': 0.05, 'batch_si...   \n",
       "13  {'epoch': 50, 'learning_rate': 0.025, 'batch_s...   \n",
       "27  {'epoch': 100, 'learning_rate': 0.05, 'batch_s...   \n",
       "0   {'epoch': 25, 'learning_rate': 0.05, 'batch_si...   \n",
       "2   {'epoch': 25, 'learning_rate': 0.05, 'batch_si...   \n",
       "12  {'epoch': 50, 'learning_rate': 0.025, 'batch_s...   \n",
       "22  {'epoch': 75, 'learning_rate': 0.025, 'batch_s...   \n",
       "31  {'epoch': 100, 'learning_rate': 0.025, 'batch_...   \n",
       "30  {'epoch': 100, 'learning_rate': 0.025, 'batch_...   \n",
       "1   {'epoch': 25, 'learning_rate': 0.05, 'batch_si...   \n",
       "9   {'epoch': 50, 'learning_rate': 0.05, 'batch_si...   \n",
       "\n",
       "    val_r2_score_wo_demeaning_nn  \n",
       "8                       0.000383  \n",
       "14                      0.000371  \n",
       "26                      0.000357  \n",
       "29                      0.000349  \n",
       "5                       0.000345  \n",
       "17                      0.000340  \n",
       "24                      0.000338  \n",
       "6                       0.000335  \n",
       "33                      0.000334  \n",
       "34                      0.000318  \n",
       "35                      0.000310  \n",
       "25                      0.000307  \n",
       "19                      0.000305  \n",
       "16                      0.000298  \n",
       "11                      0.000289  \n",
       "7                       0.000267  \n",
       "23                      0.000254  \n",
       "4                       0.000244  \n",
       "15                      0.000170  \n",
       "32                      0.000129  \n",
       "3                       0.000107  \n",
       "28                      0.000080  \n",
       "10                      0.000077  \n",
       "21                      0.000046  \n",
       "18                      0.000009  \n",
       "20                     -0.000007  \n",
       "13                     -0.000009  \n",
       "27                     -0.000020  \n",
       "0                      -0.000040  \n",
       "2                      -0.000042  \n",
       "12                     -0.000046  \n",
       "22                     -0.000096  \n",
       "31                     -0.000111  \n",
       "30                     -0.000178  \n",
       "1                      -0.000280  \n",
       "9                      -0.000713  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72842f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a928625c",
   "metadata": {},
   "source": [
    "best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a56a0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running\n",
      "finished\n",
      "best score:  -0.03544444218277931\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.03730309009552002\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  -0.03580498695373535\n",
      "start running\n",
      "finished\n",
      "best score:  -0.10656368732452393\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.05102801322937012\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  -0.13647222518920898\n",
      "start running\n",
      "finished\n",
      "best score:  -0.10287187248468399\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.06353926658630371\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  -0.07618284225463867\n",
      "start running\n",
      "finished\n",
      "best score:  -0.1627427190542221\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.04085242748260498\n",
      "335/335 [==============================] - 1s 3ms/step\n",
      "bot best:  -0.11127936840057373\n",
      "start running\n",
      "finished\n",
      "best score:  -0.12459839880466461\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.03298938274383545\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  -0.06191408634185791\n",
      "start running\n",
      "finished\n",
      "best score:  -0.1097860336303711\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.02205491065979004\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  -0.01826465129852295\n",
      "start running\n",
      "finished\n",
      "best score:  -0.11114692687988281\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.00018799304962158203\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  0.015552103519439697\n",
      "start running\n",
      "finished\n",
      "best score:  -0.06862801313400269\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "top best:  -0.002364635467529297\n",
      "335/335 [==============================] - 1s 2ms/step\n",
      "bot best:  0.062109529972076416\n"
     ]
    }
   ],
   "source": [
    "model_nn3 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(layer2_n, activation='relu'),\n",
    "            layers.Dense(layer3_n, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "last_epoch_metrics_nn3 = []\n",
    "r2_nn3_tops = []\n",
    "r2_nn3_bots = []\n",
    "\n",
    "for i in range(8):\n",
    "    print('start running')\n",
    "    model_nn3.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "    X_train_combined_nn = np.asarray(windows[i][3].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_combined_nn = np.asarray(windows[i][3]['r(t+1)'].values)\n",
    "    \n",
    "    X_test_nn = np.asarray(windows[i][2].drop(columns = ['r(t+1)']).values)\n",
    "    y_test_nn = np.asarray(windows[i][2]['r(t+1)'].values)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model_nn3.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_paras_nn3[i]['epoch'], batch_size=opt_paras_nn3[i]['batch_size'],\n",
    "                                validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "    print('finished')\n",
    "    # get scores\n",
    "    last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "    last_epoch_metrics_nn3.append(last_epoch_metric)\n",
    "    print('best score: ', last_epoch_metric)\n",
    "    \n",
    "    # top 100\n",
    "    y_pred_nn3_top = model_nn3.predict(X_test_top)\n",
    "    r2_nn3_top = r2_score_wo_demeaning(y_test_top, y_pred_nn3_top)\n",
    "    r2_nn3_tops.append(r2_nn3_top)\n",
    "    print('top best: ', r2_nn3_top)\n",
    "    \n",
    "    # bot 100\n",
    "    y_pred_nn3_bot = model_nn3.predict(X_test_bot)\n",
    "    r2_nn3_bot = r2_score_wo_demeaning(y_test_bot, y_pred_nn3_bot)\n",
    "    r2_nn3_bots.append(r2_nn3_bot)\n",
    "    print('bot best: ', r2_nn3_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df3c2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03544444218277931,\n",
       " -0.10656368732452393,\n",
       " -0.10287187248468399,\n",
       " -0.1627427190542221,\n",
       " -0.12459839880466461,\n",
       " -0.1097860336303711,\n",
       " -0.11114692687988281,\n",
       " -0.06862801313400269]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch_metrics_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58b1acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN3 average R^2-oos: -0.10272276168689132\n"
     ]
    }
   ],
   "source": [
    "print(\"NN3 average R^2-oos:\", sum(last_epoch_metrics_nn3) / len(last_epoch_metrics_nn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbd094",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f7e0c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03730309009552002,\n",
       " -0.05102801322937012,\n",
       " -0.06353926658630371,\n",
       " -0.04085242748260498,\n",
       " -0.03298938274383545,\n",
       " -0.02205491065979004,\n",
       " -0.00018799304962158203,\n",
       " -0.002364635467529297]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_nn3_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02d63c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03580498695373535,\n",
       " -0.13647222518920898,\n",
       " -0.07618284225463867,\n",
       " -0.11127936840057373,\n",
       " -0.06191408634185791,\n",
       " -0.01826465129852295,\n",
       " 0.015552103519439697,\n",
       " 0.062109529972076416]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_nn3_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e613ee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 stocks R^2-oos: -0.0312899649143219\n",
      "Bottom 100 stocks R^2-oos: -0.045282065868377686\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_nn3_tops) / len(r2_nn3_tops))\n",
    "\n",
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_nn3_bots) / len(r2_nn3_bots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a035e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee19e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn3 = pd.DataFrame(result_nn3).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "# opt_score = result_nn3.iloc[0,1]\n",
    "# opt_para = result_nn3.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e11871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn3.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed235fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_nn3.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c61569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_nn3.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para['learning_rate']),\n",
    "#                       loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "# history = model_nn3.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_para['epoch'], batch_size=opt_para['batch_size'],\n",
    "#                             validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "        \n",
    "# last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
