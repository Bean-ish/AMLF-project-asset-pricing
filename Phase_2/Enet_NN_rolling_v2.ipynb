{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e35d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdfe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/users/LL/Documents/GitHub/AMLF_projects/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9bfc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485ca046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>permno</th>\n",
       "      <th>return</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>chmom</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom36m</th>\n",
       "      <th>turn</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>...</th>\n",
       "      <th>baspread</th>\n",
       "      <th>retvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>ep</th>\n",
       "      <th>sp</th>\n",
       "      <th>agr</th>\n",
       "      <th>nincr</th>\n",
       "      <th>return(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13610</td>\n",
       "      <td>-0.202242</td>\n",
       "      <td>0.277978</td>\n",
       "      <td>-0.082232</td>\n",
       "      <td>0.518490</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>-0.258322</td>\n",
       "      <td>0.820391</td>\n",
       "      <td>9.897840e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>0.398706</td>\n",
       "      <td>0.158967</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>1.472909</td>\n",
       "      <td>0.325935</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13856</td>\n",
       "      <td>-0.112756</td>\n",
       "      <td>0.095372</td>\n",
       "      <td>0.300233</td>\n",
       "      <td>-0.147620</td>\n",
       "      <td>0.069669</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.660636</td>\n",
       "      <td>7.152231e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033983</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>0.106574</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.039970</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13901</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.166088</td>\n",
       "      <td>0.759861</td>\n",
       "      <td>0.504130</td>\n",
       "      <td>0.400659</td>\n",
       "      <td>-0.440929</td>\n",
       "      <td>0.775189</td>\n",
       "      <td>9.783550e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>0.050243</td>\n",
       "      <td>0.088382</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>1.148088</td>\n",
       "      <td>-0.024383</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13928</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.039925</td>\n",
       "      <td>0.400659</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>0.813903</td>\n",
       "      <td>1.451888e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>0.159983</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.051091</td>\n",
       "      <td>1.138525</td>\n",
       "      <td>-0.069288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>13936</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.574141</td>\n",
       "      <td>0.224657</td>\n",
       "      <td>-0.075486</td>\n",
       "      <td>-0.397110</td>\n",
       "      <td>0.755288</td>\n",
       "      <td>3.550430e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031413</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>1.060490</td>\n",
       "      <td>1.124640</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>6.902488</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  permno    return     mom1m    mom12m     chmom    indmom  \\\n",
       "0  2001-01-31   13610 -0.202242  0.277978 -0.082232  0.518490  0.198455   \n",
       "1  2001-01-31   13856 -0.112756  0.095372  0.300233 -0.147620  0.069669   \n",
       "2  2001-01-31   13901  0.010566  0.166088  0.759861  0.504130  0.400659   \n",
       "3  2001-01-31   13928  0.033114  0.006637  0.236486  0.039925  0.400659   \n",
       "4  2001-01-31   13936  0.014335  0.009709  0.574141  0.224657 -0.075486   \n",
       "\n",
       "     mom36m      turn         mvel1  ...  baspread    retvol   idiovol  \\\n",
       "0 -0.258322  0.820391  9.897840e+05  ...  0.037278  0.032888  0.056769   \n",
       "1  0.000718  0.660636  7.152231e+07  ...  0.033983  0.022389  0.042020   \n",
       "2 -0.440929  0.775189  9.783550e+07  ...  0.032844  0.023475  0.050243   \n",
       "3  0.025686  0.813903  1.451888e+07  ...  0.035964  0.023917  0.037427   \n",
       "4 -0.397110  0.755288  3.550430e+05  ...  0.031413  0.030343  0.068491   \n",
       "\n",
       "       beta    betasq        ep        sp       agr  nincr  return(t-1)  \n",
       "0  0.398706  0.158967  0.019041  1.472909  0.325935    5.0          NaN  \n",
       "1  0.106574  0.011358  0.039970  0.397105  0.225463    1.0          NaN  \n",
       "2  0.088382  0.007811  0.142695  1.148088 -0.024383    2.0          NaN  \n",
       "3  0.159983  0.025595  0.051091  1.138525 -0.069288    1.0          NaN  \n",
       "4  1.060490  1.124640  0.091598  6.902488  0.000838    0.0          NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0fa84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Index(['Date', 'permno', 'return', 'mom1m', 'mom12m', 'chmom', 'indmom',\n",
      "       'mom36m', 'turn', 'mvel1', 'dolvol', 'ill', 'zerotrade', 'baspread',\n",
      "       'retvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr',\n",
      "       'return(t-1)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cccd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64903994",
   "metadata": {},
   "source": [
    "According to note 30: \"Therefore, to predict returns at month t+1, we use most recent monthly characteristics at the end of month t.\" <br>\n",
    "Hence, **shift return t+1 to serve as response: r(t+1)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r(t+1)'] = df.groupby('permno')['return'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1d5769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1521d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110f651",
   "metadata": {},
   "source": [
    "### handle missing data\n",
    "\n",
    "According to note 30 (bottom of p 2248): \"Another issue is missing characteristics, which we replace with the cross-sectional median at each month for each stock, respectively.\" <br>\n",
    "Hence, calculate monthly cross-sectional median for features: **'mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581efc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.copy()\n",
    "for feature in ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']:\n",
    "    df_filled[feature] = df_filled.groupby('Date')[feature].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8094662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d22efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']] = df_filled.loc[:,['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9379e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "permno           0\n",
       "return           0\n",
       "mom1m            0\n",
       "mom12m           0\n",
       "chmom            0\n",
       "indmom           0\n",
       "mom36m           0\n",
       "turn             0\n",
       "mvel1            0\n",
       "dolvol           0\n",
       "ill              0\n",
       "zerotrade        0\n",
       "baspread         0\n",
       "retvol           0\n",
       "idiovol          0\n",
       "beta             0\n",
       "betasq           0\n",
       "ep               0\n",
       "sp               0\n",
       "agr              0\n",
       "nincr            0\n",
       "return(t-1)    500\n",
       "r(t+1)         500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4352d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the datetime column as index\n",
    "df.set_index('Date', inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1f46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff8f4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "permno = df['permno'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['permno'] = permno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a730d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5993c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_2 = df_scaled.drop(columns = [ 'permno', 'return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4ab11",
   "metadata": {},
   "source": [
    "### importing custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0946f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"C:/users/LL/Documents/GitHub/AMLF_projects/pj1_functions.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cea22",
   "metadata": {},
   "source": [
    "### spliting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ed881",
   "metadata": {},
   "source": [
    "**generate rolling windows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5a4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling samples\n",
    "\n",
    "windows = generate_rolling_windows(df_scaled_2, 19, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39a02f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in windows:\n",
    "    mean = window[0]['r(t+1)'].mean()\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab15222",
   "metadata": {},
   "source": [
    "### subsampling data\n",
    "top and bottom 100 stocks on market value (mvel1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94061e3d",
   "metadata": {},
   "source": [
    "**get top 100 and bot 100 of all years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvel_sorted_top = subset['2019-12-01':].sort_values('mvel1',ascending=False).head(100).reset_index(drop=True)\n",
    "filter_values_top = mvel_sorted_top['permno']\n",
    "top_100 = subset[subset['permno'].isin(filter_values_top)]\n",
    "\n",
    "\n",
    "mvel_sorted_bot = subset['2019-12-01':].sort_values('mvel1',ascending=False).tail(100).reset_index(drop=True)\n",
    "filter_values_bot = mvel_sorted_bot['permno']\n",
    "bot_100 = subset[subset['permno'].isin(filter_values_bot)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ff898",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100.shape\n",
    "# 19*12*10 = 2280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03273f",
   "metadata": {},
   "source": [
    "**splitting data & separating X and y** <br>\n",
    "splitting data 10:9 years - to make the training set the same size as the training and validation set combined, leave testing set out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1fb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_windows = generate_rolling_windows(top_100.dropna(), 19, 6, 4)\n",
    "# bot_windows = generate_rolling_windows(bot_100.dropna(), 19, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(top_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bot_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_top = top_100[:'2011-01-01'].dropna()\n",
    "testing_top = top_100['2011-01-02':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bot = bot_100[:'2011-01-01'].dropna()\n",
    "testing_bot = bot_100['2011-01-02':].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e2063",
   "metadata": {},
   "source": [
    "separating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_top = testing_top.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test_top = testing_top['r(t+1)']\n",
    "\n",
    "X_test_bot = testing_bot.drop(columns = ['permno', 'return', 'r(t+1)'])\n",
    "y_test_bot = testing_bot['r(t+1)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ce901",
   "metadata": {},
   "source": [
    "# Enet\n",
    "\n",
    "\n",
    "prediction: g*(z i,t) - depends on neither i nor t, is dependend on z only through z i,t <br>\n",
    "responses: r i, t+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf763cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d566281",
   "metadata": {},
   "source": [
    "**tuning**\n",
    "\n",
    "1. set-up the search grid\n",
    "2. tuning: recursive rolling validation set w/ oos R^2 metric -- <br>\n",
    "    roll one unit froward each time and take the average as the final score <br>\n",
    "3. pick the best hyperparameters, retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b1cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up searching grid\n",
    "\n",
    "alpha_values = [0.4, 0.5, 0.6]\n",
    "l1_ratio_values = np.logspace(-4, -1, 10)\n",
    "\n",
    "param_enet = [{'alpha': alpha, 'l1_ratio': l1_ratio} for alpha in alpha_values for l1_ratio in l1_ratio_values]\n",
    "\n",
    "# for param_combination in param_combinations:\n",
    "#     print(param_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "027fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "\n",
    "Enet = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d6424ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is 0.0007755796797865866.\n",
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is 0.002077004617268674.\n",
      "the optimal parameters are {'alpha': 0.6, 'l1_ratio': 0.1} and the best score is -0.0014524607777255394.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0063834100482236256.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.004957498963627627.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0035499187056395876.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0012202180037492738.\n",
      "the optimal parameters are {'alpha': 0.4, 'l1_ratio': 0.0001} and the best score is -0.0022601722569968175.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for window in windows:\n",
    "    \n",
    "    #apply tuning function\n",
    "    result = tuning_1(Enet, param_enet, window[0].drop(columns = ['r(t+1)']), window[0]['r(t+1)'], window[1].drop(columns = ['r(t+1)']), window[1]['r(t+1)'])\n",
    "    \n",
    "    # print out tuning parameters of eah]ch split\n",
    "    print(f\"the optimal parameters are {result[0]} and the best score is {result[1]}.\")\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34013615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bedc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f2c02ec",
   "metadata": {},
   "source": [
    "**best model** <br>\n",
    "<br>\n",
    "Fit on all data in training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d106cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Enet_opt = ElasticNet()\n",
    "r2_Enet = []\n",
    "# r2_Enet_top = []\n",
    "# r2_Enet_bot = []\n",
    "for i in range(8):\n",
    "    \n",
    "    for param_name, param_value in results[i][0].items():\n",
    "     setattr(Enet_opt, param_name, param_value)\n",
    "    \n",
    "    Enet_opt.fit(windows[i][3].drop(columns = ['r(t+1)']), windows[i][3]['r(t+1)'])\n",
    "    y_pred_enet = Enet_opt.predict(windows[i][2].drop(columns = ['r(t+1)']))\n",
    "    \n",
    "    r2_enet = r2_score_wo_demeaning(windows[i][2]['r(t+1)'], y_pred_enet)\n",
    "    r2_Enet.append(r2_enet)       # fit best model for each split\n",
    "    \n",
    "    # used model to generate prediction for the top 100\n",
    "#     y_pred_enet_top = Enet_opt.predict(X_test_top)\n",
    "#     r2_enet_top = r2_score_wo_demeaning(y_test_top, y_pred_enet_top)\n",
    "#     r2_Enet_top.append(r2_enet_top)\n",
    "    \n",
    "#     y_pred_enet_bot = Enet_opt.predict(X_test_bot)\n",
    "#     r2_enet_bot = r2_score_wo_demeaning(y_test_bot, y_pred_enet_bot)\n",
    "#     r2_Enet_bot.append(r2_enet_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ecffeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005663579684225262,\n",
       " 0.0007243052297416508,\n",
       " 0.00015885305985385845,\n",
       " -0.001960710816258926,\n",
       " -0.0008903639645345685,\n",
       " 2.6038543099682343e-05,\n",
       " -0.002316165787667135,\n",
       " -0.00016025654555895663]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the best r^2-oos for 8 splits stored in one list:\n",
    "\n",
    "r2_Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e15f001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2-oos: -0.0004814927891127335\n"
     ]
    }
   ],
   "source": [
    "#take average\n",
    "\n",
    "print(\"R^2-oos:\", sum(r2_Enet) / len(r2_Enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091852f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71740d28",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_Enet_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c324fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take average\n",
    "\n",
    "# print(\"Top 100 stocks R^2-oos:\", sum(r2_Enet_top) / len(r2_Enet_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f088ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_Enet_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12d2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take average\n",
    "\n",
    "# print(\"Bottom 100 stocks R^2-oos:\", sum(r2_Enet_bot) / len(r2_Enet_bot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77969a4c",
   "metadata": {},
   "source": [
    "**feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# coefficients = Enet_opt.coef_\n",
    "\n",
    "# # Get feature names\n",
    "# # Assuming feature_names is a list of your feature names\n",
    "# feature_names = X_train_combined.columns  # Insert your feature names here\n",
    "\n",
    "# # Create a dictionary to store feature importance scores with feature names\n",
    "# feature_importance_dict = dict(zip(feature_names, np.abs(coefficients)))\n",
    "\n",
    "# # Sort feature importance dictionary by importance score\n",
    "# sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Extract feature names and importance scores after sorting\n",
    "# sorted_feature_names = [x[0] for x in sorted_feature_importance]\n",
    "# sorted_feature_importance_scores = [x[1] for x in sorted_feature_importance]\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.barh(sorted_feature_names, sorted_feature_importance_scores)\n",
    "# plt.xlabel('Feature Importance')\n",
    "# plt.ylabel('Features')\n",
    "# plt.title('Feature Importance of Elastic Net Model')\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to have the most important features at the top\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2054aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f12888",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca69c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f85419",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "All activation functions are ReLU function <br>\n",
    "optimizer: SGD w/ learning rate shrinkage: adam <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4b2d0",
   "metadata": {},
   "source": [
    "set-up grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72655500",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch_val = [25, 50, 75, 100]\n",
    "lr_val = [0.05, 0.01, 0.001]\n",
    "nbatch_val = [1500, 2500, 3500]\n",
    "\n",
    "param_nn = [{'epoch': epoch, 'learning_rate': learning_rate, 'batch_size': batch_size} for epoch in nepoch_val for learning_rate in lr_val for batch_size in nbatch_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1f391",
   "metadata": {},
   "source": [
    "### 1-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4beffabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 20\n",
    "layer1_n = 32\n",
    "\n",
    "model_1 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc86773",
   "metadata": {},
   "source": [
    "**tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f097c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn1 = []\n",
    "opt_scores_nn1 = []\n",
    "opt_paras_nn1 = []\n",
    "\n",
    "for window in windows:\n",
    "    print(\"start running\")\n",
    "    # to arry\n",
    "    X_train_nn = np.asarray(window[0].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_nn = np.asarray(window[0]['r(t+1)'].values)\n",
    "\n",
    "    X_val_nn = np.asarray(window[1].drop(columns = ['r(t+1)']).values)\n",
    "    y_val_nn = np.asarray(window[1]['r(t+1)'].values)\n",
    "    \n",
    "    # apply function\n",
    "    result_nn1 = compile_and_tune_model(model_1, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n",
    "    \n",
    "    # get score\n",
    "    result_nn1 = pd.DataFrame(result_nn1).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "    print('finished')\n",
    "    opt_score = result_nn1.iloc[0,1]\n",
    "    print(\"opt_score: \", opt_score)\n",
    "    opt_para = result_nn1.iloc[0,0]\n",
    "    print(\"opt_result: \", opt_para)\n",
    "    # results_nn1.append(result_nn1.iloc[0,])\n",
    "    opt_scores_nn1.append(opt_score)\n",
    "    opt_paras_nn1.append(opt_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcdc47",
   "metadata": {},
   "source": [
    "**best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn1 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "last_epoch_metrics = []\n",
    "r2_nn1_tops = []\n",
    "r2_nn1_bots = []\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    model_nn1.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_paras_nn1[i]['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "    X_train_combined_nn = np.asarray(windows[i][3].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_combined_nn = np.asarray(windows[i][3]['r(t+1)'].values)\n",
    "    \n",
    "    X_test_nn = np.asarray(windows[i][2].drop(columns = ['r(t+1)']).values)\n",
    "    y_test_nn = np.asarray(windows[i][2]['r(t+1)'].values)\n",
    "    \n",
    "    # fit the model\n",
    "    print('start fitting')\n",
    "    history = model_nn1.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_paras_nn1[i]['epoch'], batch_size=opt_paras_nn1[i]['batch_size'],\n",
    "                                validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "    print('finished fitting')\n",
    "    \n",
    "    # get scores\n",
    "    last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "    last_epoch_metrics.append(last_epoch_metric)\n",
    "    print('best score: ', last_epoch_metric)\n",
    "    \n",
    "    # top 100\n",
    "    y_pred_nn1_top = model_nn1.predict(X_test_top)\n",
    "    r2_nn1_top = r2_score_wo_demeaning(y_test_top, y_pred_nn1_top)\n",
    "    r2_nn1_tops.append(r2_nn1_top)\n",
    "    print('top best score: ', r2_nn1_top)\n",
    "    \n",
    "    # bot 100\n",
    "    y_pred_nn1_bot = model_nn1.predict(X_test_bot)\n",
    "    r2_nn1_bot = r2_score_wo_demeaning(y_test_bot, y_pred_nn1_bot)\n",
    "    r2_nn1_bots.append(r2_nn1_bot)\n",
    "    print('bot best score: ', r2_nn1_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NN1 average R^2-oos:\", sum(last_epoch_metrics) / len(last_epoch_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f2aeb",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3259fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn1_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_nn1_tops) / len(r2_nn1_tops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f893d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn1_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c87e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_nn1_bots) / len(r2_nn1_bots))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d8800",
   "metadata": {},
   "source": [
    "### 3-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 20\n",
    "layer1_n = 32\n",
    "layer2_n = 16\n",
    "layer3_n = 8\n",
    "\n",
    "\n",
    "model_3 = Sequential([\n",
    "            layers.Dense(layer1_n, input_dim = input_dim, activation='relu'),\n",
    "            layers.Dense(layer2_n, activation='relu'),\n",
    "            layers.Dense(layer3_n, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a2cd7",
   "metadata": {},
   "source": [
    "**tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn3 = []\n",
    "opt_scores_nn3 = []\n",
    "opt_paras_nn3 = []\n",
    "\n",
    "for window in windows:\n",
    "    print('start running')\n",
    "    # to arry\n",
    "    X_train_nn = np.asarray(window[0].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_nn = np.asarray(window[0]['r(t+1)'].values)\n",
    "\n",
    "    X_val_nn = np.asarray(window[1].drop(columns = ['r(t+1)']).values)\n",
    "    y_val_nn = np.asarray(window[1]['r(t+1)'].values)\n",
    "\n",
    "    result_nn3 = compile_and_tune_model(model_3, param_nn, X_train_nn, y_train_nn, X_val_nn, y_val_nn)\n",
    "    print('finished running')\n",
    "    \n",
    "    # get score\n",
    "    result_nn3 = pd.DataFrame(result_nn3).sort_values('val_r2_score_wo_demeaning_nn',ascending=False)\n",
    "    opt_score = result_nn3.iloc[0,1]\n",
    "    print('opt_score: ', opt_score)\n",
    "    opt_para = result_nn3.iloc[0,0]\n",
    "    print('opt_para: ', opt_para)\n",
    "    # results_nn1.append(result_nn1.iloc[0,])\n",
    "    opt_scores_nn3.append(opt_score)\n",
    "    opt_paras_nn3.append(opt_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecce5e",
   "metadata": {},
   "source": [
    "check one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th split\n",
    "# 2001-2013; 2014-2019\n",
    "parameters = {'epoch': 25, 'learning_rate': 0.01, 'batch_size': 3000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr4 = windows[3][3].drop(columns = ['r(t+1)'])\n",
    "y_tr4 = windows[3][3]['r(t+1)']\n",
    "\n",
    "X_ts4 = windows[3][2].drop(columns = ['r(t+1)'])\n",
    "y_ts4 = windows[3][2]['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn3_4 = Sequential([\n",
    "            layers.Dense(32, activation='relu', input_dim=20),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(8, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "print('start fitting')\n",
    "\n",
    "model_nn3_4.compile(optimizer=keras.optimizers.Adam(learning_rate=parameters['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "X_train_combined_nn3_4 = np.asarray(X_tr4.values)\n",
    "y_train_combined_nn3_4 = np.asarray(y_tr4.values)\n",
    "\n",
    "X_test_nn3_4 = np.asarray(X_ts4.values)\n",
    "y_test_nn3_4 = np.asarray(y_ts4.values)\n",
    "    \n",
    "outcome = model_nn3_4.fit(X_train_combined_nn3_4, y_train_combined_nn3_4, epochs=parameters['epoch'], batch_size=parameters['batch_size'],verbose=0)\n",
    "print('finished')\n",
    "# get scores\n",
    "# R2_nn3_4 = outcome.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "# print('best score: ', R2_nn3_4)\n",
    "\n",
    "pred_nn4 = model_nn3_4.predict(X_test_nn3_4)\n",
    "score = r2_score_wo_demeaning(y_test_nn3_4, pred_nn4)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928625c",
   "metadata": {},
   "source": [
    "**best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a56a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn3 = Sequential([\n",
    "            layers.Dense(layer1_n, activation='relu', input_dim=input_dim),\n",
    "            layers.Dense(layer2_n, activation='relu'),\n",
    "            layers.Dense(layer3_n, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "last_epoch_metrics_nn3 = []\n",
    "r2_nn3_tops = []\n",
    "r2_nn3_bots = []\n",
    "\n",
    "for i in range(8):\n",
    "    print('start running')\n",
    "    model_nn3.compile(optimizer=keras.optimizers.Adam(learning_rate=opt_para_nn3[i]['learning_rate']),\n",
    "                          loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "    X_train_combined_nn = np.asarray(windows[i][3].drop(columns = ['r(t+1)']).values)\n",
    "    y_train_combined_nn = np.asarray(windows[i][3]['r(t+1)'].values)\n",
    "    \n",
    "    X_test_nn = np.asarray(windows[i][2].drop(columns = ['r(t+1)']).values)\n",
    "    y_test_nn = np.asarray(windows[i][2]['r(t+1)'].values)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model_nn3.fit(X_train_combined_nn, y_train_combined_nn, epochs=opt_paras_nn3[i]['epoch'], batch_size=opt_paras_nn3[i]['batch_size'],\n",
    "                                validation_data=(X_test_nn, y_test_nn), verbose=0)\n",
    "    print('finished')\n",
    "    # get scores\n",
    "    last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "    last_epoch_metrics_nn3.append(last_epoch_metric)\n",
    "    print('best score: ', last_epoch_metric)\n",
    "    \n",
    "    # top 100\n",
    "    y_pred_nn3_top = model_nn3.predict(X_test_top)\n",
    "    r2_nn3_top = r2_score_wo_demeaning(y_test_top, y_pred_nn3_top)\n",
    "    r2_nn3_tops.append(r2_nn3_top)\n",
    "    print('top best: ', r2_nn3_top)\n",
    "    \n",
    "    # bot 100\n",
    "    y_pred_nn3_bot = model_nn3.predict(X_test_bot)\n",
    "    r2_nn3_bot = r2_score_wo_demeaning(y_test_bot, y_pred_nn3_bot)\n",
    "    r2_nn3_bots.append(r2_nn3_bot)\n",
    "    print('bot best: ', r2_nn3_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch_metrics_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NN3 average R^2-oos:\", sum(last_epoch_metrics_nn3) / len(last_epoch_metrics_nn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbd094",
   "metadata": {},
   "source": [
    "**top and bottom 100 prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn3_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 100 stocks R^2-oos:\", sum(r2_nn3_tops) / len(r2_nn3_tops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d63c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_nn3_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bottom 100 stocks R^2-oos:\", sum(r2_nn3_bots) / len(r2_nn3_bots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a035e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee19e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
